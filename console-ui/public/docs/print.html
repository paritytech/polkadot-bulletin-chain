<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Polkadot Bulletin Chain Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-c08dc049.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-5689f54b.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Polkadot Bulletin Chain Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/paritytech/polkadot-bulletin-chain" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="polkadot-bulletin-chain"><a class="header" href="#polkadot-bulletin-chain">Polkadot Bulletin Chain</a></h1>
<p>Welcome to the official documentation for the <strong>Polkadot Bulletin Chain</strong> - a decentralized storage ledger for the Polkadot ecosystem.</p>
<h2 id="what-is-bulletin-chain"><a class="header" href="#what-is-bulletin-chain">What is Bulletin Chain?</a></h2>
<p>Polkadot Bulletin Chain is a specialized blockchain that provides <strong>distributed data storage and retrieval infrastructure</strong>. It allows users to:</p>
<ul>
<li><strong>Store</strong> arbitrary data on-chain with proof-of-storage guarantees</li>
<li><strong>Retrieve</strong> data via IPFS using content-addressed identifiers (CIDs)</li>
<li><strong>Verify</strong> data existence and timestamps through blockchain consensus</li>
</ul>
<p>Unlike typical file storage systems (like Filecoin or Arweave), Bulletin Chain focuses on:</p>
<ol>
<li><strong>Immutability</strong>: Once a CID is on-chain, it cannot be changed</li>
<li><strong>Verifiability</strong>: Data is content-addressed using standard IPFS CIDs</li>
<li><strong>Flexibility</strong>: Supports both small direct storage and large chunked storage</li>
<li><strong>Integration</strong>: Seamlessly works with standard IPFS tools and gateways</li>
</ol>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Step</th><th>Concept</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td>1</td><td><strong>Authorize</strong></td><td>Get permission to store (faucet on testnet)</td></tr>
<tr><td>2</td><td><strong>Store</strong></td><td>Submit data to the chain, receive a CID</td></tr>
<tr><td>3</td><td><strong>Retrieve</strong></td><td>Fetch data via IPFS using the CID</td></tr>
<tr><td>4</td><td><strong>Renew</strong></td><td>Extend storage before the retention period expires</td></tr>
</tbody>
</table>
</div>
<h2 id="accessing-bulletin-chain"><a class="header" href="#accessing-bulletin-chain">Accessing Bulletin Chain</a></h2>
<p>There are multiple ways to interact with Bulletin Chain:</p>
<h3 id="sdks-recommended"><a class="header" href="#sdks-recommended">SDKs (Recommended)</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Language</th><th>Package</th><th>Status</th></tr>
</thead>
<tbody>
<tr><td><strong>Rust</strong></td><td><code>bulletin-sdk-rust</code></td><td>Alpha</td></tr>
<tr><td><strong>TypeScript</strong></td><td><code>@bulletin/sdk</code></td><td>Alpha</td></tr>
</tbody>
</table>
</div>
<p>The SDKs provide high-level abstractions for:</p>
<ul>
<li>Automatic data chunking for large files</li>
<li>CID calculation (IPFS-compatible)</li>
<li>DAG-PB manifest generation</li>
<li>Authorization management</li>
</ul>
<h3 id="ipfs"><a class="header" href="#ipfs">IPFS</a></h3>
<p>Data retrieval happens through IPFS:</p>
<ul>
<li>Public gateways: <code>https://ipfs.io/ipfs/{cid}</code></li>
<li>Direct from Bulletin nodes via Bitswap protocol</li>
<li>Standard <code>ipfs</code> CLI tools</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<pre><code class="language-typescript">// TypeScript - Store data
import { BulletinClient } from "@bulletin/sdk";

const client = new BulletinClient();
const data = new TextEncoder().encode("Hello, Bulletin!");
const operation = client.prepareStore(data);

// Submit via PAPI, get CID back
// ...

// Retrieve via IPFS gateway
const response = await fetch(`https://ipfs.io/ipfs/${cid}`);
</code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Rust - Store data
use bulletin_sdk_rust::prelude::*;

let client = BulletinClient::new();
let data = b"Hello, Bulletin!".to_vec();
let operation = client.prepare_store(data, None)?;

// Submit via subxt, get CID back
// ...

// Retrieve via IPFS gateway
let response = reqwest::get(format!("https://ipfs.io/ipfs/{}", cid)).await?;
<span class="boring">}</span></code></pre>
<h2 id="networks"><a class="header" href="#networks">Networks</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Network</th><th>Endpoint</th><th>Status</th></tr>
</thead>
<tbody>
<tr><td>Paseo (Testnet)</td><td><code>wss://paseo-bulletin-rpc.polkadot.io</code></td><td>Active</td></tr>
<tr><td>Westend (Testnet)</td><td><code>wss://westend-bulletin-rpc.polkadot.io</code></td><td>Active</td></tr>
<tr><td>Dotspark</td><td><code>wss://bulletin.dotspark.app</code></td><td>Active</td></tr>
<tr><td>Local Dev</td><td><code>ws://localhost:10000</code></td><td>-</td></tr>
</tbody>
</table>
</div>
<p>See <a href="https://github.com/paritytech/polkadot-bulletin-chain/blob/main/shared/networks.json">shared/networks.json</a> for the full configuration.</p>
<h2 id="documentation-structure"><a class="header" href="#documentation-structure">Documentation Structure</a></h2>
<ul>
<li><strong><a href="concepts/README.html">Core Concepts</a></strong> - Understand how Bulletin Chain works
<ul>
<li>Storage model, authorization, manifests, retrieval, renewal</li>
</ul>
</li>
<li><strong><a href="rust/README.html">Rust SDK</a></strong> - Native Rust client
<ul>
<li>Supports <code>std</code> and <code>no_std</code> (WASM)</li>
</ul>
</li>
<li><strong><a href="typescript/README.html">TypeScript SDK</a></strong> - JS/TS client
<ul>
<li>Node.js and Browser, integrates with PAPI</li>
</ul>
</li>
</ul>
<h2 id="building-this-documentation"><a class="header" href="#building-this-documentation">Building This Documentation</a></h2>
<p>This documentation is built using <a href="https://github.com/rust-lang/mdBook">mdBook</a>.</p>
<pre><code class="language-bash"># Install mdbook
cargo install mdbook

# Serve locally with live reload
cd docs/book
mdbook serve --open

# Build static HTML
mdbook build
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h1>
<p>This section covers the fundamental concepts you need to understand when working with Bulletin Chain.</p>
<h2 id="data-lifecycle"><a class="header" href="#data-lifecycle">Data Lifecycle</a></h2>
<pre><code>1. AUTHORIZE       2. STORE           3. RETRIEVE        4. RENEW
   ↓                  ↓                  ↓                  ↓
Get permission    Submit data       Fetch via IPFS    Extend retention
(faucet/sudo)     + receive CID     using CID         before expiration
</code></pre>
<h3 id="1-authorization-faucet"><a class="header" href="#1-authorization-faucet">1. Authorization (Faucet)</a></h3>
<p>Before storing data, accounts must be <strong>authorized</strong>. This prevents spam and manages storage costs.</p>
<ul>
<li>Use the <strong>Faucet</strong> (testnet) or request authorization from a Root/Sudo user</li>
<li>Authorization grants permission to store a specified amount of data (bytes + transactions)</li>
<li>Authorization can be for an account or a specific content hash (preimage)</li>
<li>Learn more: <a href="#authorization">Authorization</a></li>
</ul>
<h3 id="2-storage"><a class="header" href="#2-storage">2. Storage</a></h3>
<p>Once authorized, submit data to the chain:</p>
<ul>
<li><strong>Small data</strong> (&lt; 8 MiB): Stored directly in a single transaction</li>
<li><strong>Large data</strong> (&gt; 8 MiB): Split into chunks with a DAG-PB manifest</li>
<li>On success, you receive:
<ul>
<li><strong>CID</strong> (Content Identifier) for retrieval</li>
<li><strong>Block number</strong> and <strong>index</strong> (needed for renewal)</li>
</ul>
</li>
<li>Learn more: <a href="#storage-models">Storage Model</a></li>
</ul>
<h3 id="3-retrieval"><a class="header" href="#3-retrieval">3. Retrieval</a></h3>
<p>Data is retrieved via <strong>IPFS</strong>, not directly from the chain:</p>
<ul>
<li>Use any IPFS gateway: <code>https://ipfs.io/ipfs/{cid}</code></li>
<li>Connect directly to Bulletin nodes via Bitswap protocol</li>
<li>Chunked data is automatically reassembled by IPFS</li>
<li>Learn more: <a href="#data-retrieval">Data Retrieval</a></li>
</ul>
<h3 id="4-renewal"><a class="header" href="#4-renewal">4. Renewal</a></h3>
<p>Data has a <strong>retention period</strong> after which it may be pruned:</p>
<ul>
<li>Track the block number and index from <code>Stored</code>/<code>Renewed</code> events</li>
<li>Call <code>renew(block, index)</code> before expiration to extend retention</li>
<li>Each renewal gives you a <strong>new</strong> block/index for the next renewal</li>
<li>Learn more: <a href="#data-renewal">Data Renewal</a></li>
</ul>
<h2 id="cids-content-identifiers"><a class="header" href="#cids-content-identifiers">CIDs (Content Identifiers)</a></h2>
<p>Bulletin Chain uses <strong>CIDs</strong> to identify data. A CID is a self-describing label used in IPFS:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Component</th><th>Description</th><th>Example</th></tr>
</thead>
<tbody>
<tr><td><strong>Version</strong></td><td>CID version</td><td><code>1</code> (CIDv1)</td></tr>
<tr><td><strong>Codec</strong></td><td>Data format</td><td><code>0x55</code> (Raw), <code>0x70</code> (DAG-PB)</td></tr>
<tr><td><strong>Multihash</strong></td><td>Hash algorithm</td><td><code>blake2b-256</code>, <code>sha2-256</code></td></tr>
</tbody>
</table>
</div>
<p>When you store data, the chain records the CID. This proves that <em>this specific data</em> existed at <em>this specific block number</em>.</p>
<h2 id="data-limits"><a class="header" href="#data-limits">Data Limits</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Limit</th><th>Value</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>Max Transaction Size</td><td>~8 MiB</td><td>Substrate limit</td></tr>
<tr><td>Recommended Chunk Size</td><td>1 MiB</td><td>Optimal for most use cases</td></tr>
<tr><td>Retention Period</td><td>Chain-specific</td><td>Check <code>transactionStorage.retentionPeriod()</code></td></tr>
</tbody>
</table>
</div>
<p>Files larger than the transaction limit must be chunked. The SDKs handle this automatically.</p>
<h2 id="sections"><a class="header" href="#sections">Sections</a></h2>
<ul>
<li><a href="#authorization">Authorization</a> - Getting permission to store (faucet)</li>
<li><a href="#storage-models">Storage Model</a> - How data is stored on-chain</li>
<li><a href="#data-retrieval">Data Retrieval</a> - Fetching data via IPFS</li>
<li><a href="#data-renewal">Data Renewal</a> - Extending storage retention</li>
<li><a href="#manifests--ipfs">Manifests &amp; IPFS</a> - DAG-PB format for chunked data</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="authorization"><a class="header" href="#authorization">Authorization</a></h1>
<p>Before storing data, you must be <strong>authorized</strong>. This mechanism prevents spam and ensures fair usage of chain storage.</p>
<h2 id="who-can-authorize"><a class="header" href="#who-can-authorize">Who Can Authorize?</a></h2>
<p>Authorization is granted by <strong>privileged accounts</strong>:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Network</th><th>Authorizer</th><th>How to Request</th></tr>
</thead>
<tbody>
<tr><td><strong>Testnets</strong> (Paseo, Westend)</td><td><a href="#finding-the-sudo-account">Sudo account</a></td><td>Use the <strong>Faucet</strong> in the Console UI</td></tr>
<tr><td><strong>Dotspark</strong></td><td><a href="#finding-the-sudo-account">Sudo account</a></td><td>Use the Faucet or contact operators</td></tr>
<tr><td><strong>Mainnet</strong> (Polkadot)</td><td>Governance (ideally)</td><td>Contact chain operators for now</td></tr>
</tbody>
</table>
</div>
<h3 id="finding-the-sudo-account"><a class="header" href="#finding-the-sudo-account">Finding the Sudo Account</a></h3>
<p>The sudo account for each network can be queried on-chain:</p>
<pre><code class="language-typescript">// Query the current sudo key
const sudoKey = await api.query.Sudo.Key.getValue();
console.log("Sudo account:", sudoKey);
</code></pre>
<p>Or check the <strong>Dashboard</strong> in the Console UI - the sudo account is displayed in the chain info section when connected.</p>
<h3 id="using-the-faucet-testnets"><a class="header" href="#using-the-faucet-testnets">Using the Faucet (Testnets)</a></h3>
<p>The easiest way to get authorization on testnets:</p>
<ol>
<li>Open the <strong>Console UI</strong> (you’re likely already here!)</li>
<li>Connect your wallet (Polkadot.js, Talisman, etc.)</li>
<li>Navigate to <strong>Faucet</strong> in the menu</li>
<li>Request authorization for your account</li>
<li>The faucet will grant you a default allocation (transactions + bytes)</li>
</ol>
<h3 id="for-application-developers"><a class="header" href="#for-application-developers">For Application Developers</a></h3>
<p>If you’re building an application that needs authorization:</p>
<ul>
<li><strong>Testnets</strong>: Use the faucet or run your own node with sudo access</li>
<li><strong>Production</strong>: Contact the chain operators or submit a governance proposal</li>
</ul>
<h3 id="running-your-own-node-local-development"><a class="header" href="#running-your-own-node-local-development">Running Your Own Node (Local Development)</a></h3>
<p>For local development, you have sudo access:</p>
<pre><code class="language-bash"># Start a local dev node
./polkadot-bulletin-chain --dev

# The //Alice account has sudo privileges
# Use it to authorize other accounts
</code></pre>
<h2 id="types-of-authorization"><a class="header" href="#types-of-authorization">Types of Authorization</a></h2>
<h3 id="1-account-authorization-authorize_account"><a class="header" href="#1-account-authorization-authorize_account">1. Account Authorization (<code>authorize_account</code>)</a></h3>
<p>Authorizes a specific <strong>account</strong> to store data up to a limit.</p>
<ul>
<li><strong>Flexible</strong>: The account can store <em>any</em> data</li>
<li><strong>Best for</strong>: Active users, applications with dynamic content</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>who</code>: The account to authorize</li>
<li><code>transactions</code>: Number of storage transactions allowed</li>
<li><code>bytes</code>: Total bytes allowed</li>
</ul>
<h3 id="2-preimage-authorization-authorize_preimage"><a class="header" href="#2-preimage-authorization-authorize_preimage">2. Preimage Authorization (<code>authorize_preimage</code>)</a></h3>
<p>Authorizes a specific <strong>piece of data</strong> (by hash) to be stored by anyone.</p>
<ul>
<li><strong>Restricted</strong>: Only data matching the hash can be stored</li>
<li><strong>Best for</strong>: Sponsored uploads, known content</li>
</ul>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>content_hash</code>: Hash of the data to authorize</li>
<li><code>max_size</code>: Maximum size of the data</li>
</ul>
<h2 id="checking-your-authorization"><a class="header" href="#checking-your-authorization">Checking Your Authorization</a></h2>
<p>Query your current authorization status:</p>
<pre><code class="language-typescript">// TypeScript (PAPI)
const auth = await api.query.TransactionStorage.Authorizations.getValue(accountId);
if (auth) {
  console.log(`Transactions remaining: ${auth.transactions}`);
  console.log(`Bytes remaining: ${auth.bytes}`);
}
</code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Rust (subxt)
let auth = api
    .storage()
    .at_latest()
    .await?
    .fetch(&amp;bulletin::storage().transaction_storage().authorizations(account_id))
    .await?;
<span class="boring">}</span></code></pre>
<h2 id="estimating-authorization-needs"><a class="header" href="#estimating-authorization-needs">Estimating Authorization Needs</a></h2>
<p>Use the SDK to calculate how much authorization you need:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Rust
let client = BulletinClient::new();
let (txs, bytes) = client.estimate_authorization(file_size_in_bytes);
println!("Need {} transactions and {} bytes", txs, bytes);
<span class="boring">}</span></code></pre>
<pre><code class="language-typescript">// TypeScript
const client = new BulletinClient();
const { transactions, bytes } = client.estimateAuthorization(fileSizeInBytes);
console.log(`Need ${transactions} transactions and ${bytes} bytes`);
</code></pre>
<p><strong>Example Calculation</strong> (100 MiB file with 1 MiB chunks):</p>
<ul>
<li>Chunks: 100</li>
<li>Manifest: 1</li>
<li><strong>Total Transactions</strong>: 101</li>
<li><strong>Total Bytes</strong>: ~100 MiB + manifest overhead</li>
</ul>
<h2 id="authorization-expiry"><a class="header" href="#authorization-expiry">Authorization Expiry</a></h2>
<p>Authorization may have an optional expiry block:</p>
<ul>
<li>If set, authorization becomes invalid after that block</li>
<li>Unused authorization is not refunded</li>
<li>Plan your uploads accordingly</li>
</ul>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li><a href="#storage-models">Storage Model</a> - How to store data</li>
<li><a href="#data-retrieval">Data Retrieval</a> - Fetching stored data</li>
<li><a href="#data-renewal">Data Renewal</a> - Extending retention</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="storage-models"><a class="header" href="#storage-models">Storage Models</a></h1>
<p>The SDK supports two primary modes of operation.</p>
<h2 id="simple-storage-direct"><a class="header" href="#simple-storage-direct">Simple Storage (Direct)</a></h2>
<p>For small data (less than 8 MiB), you can store the data directly in a single transaction.</p>
<ul>
<li><strong>Pros</strong>: Simple, atomic (all or nothing).</li>
<li><strong>Cons</strong>: Limited by block size and transaction size limits.</li>
<li><strong>Underlying Call</strong>: <code>TransactionStorage.store(data)</code></li>
</ul>
<p>The SDK calculates the CID for you and wraps the data in a <code>StorageOperation</code>.</p>
<h2 id="chunked-storage-dag-pb"><a class="header" href="#chunked-storage-dag-pb">Chunked Storage (DAG-PB)</a></h2>
<p>For larger files, the data is split into a <strong>Merkle DAG</strong> (Directed Acyclic Graph).</p>
<ol>
<li><strong>Chunking</strong>: The file is split into 1 MiB chunks.</li>
<li><strong>Upload</strong>: Each chunk is uploaded as a separate transaction.</li>
<li><strong>Manifest</strong>: A “Manifest” node is created. This is a small Protobuf message that lists the links (CIDs) to all the chunks.</li>
<li><strong>Finalize</strong>: The Manifest is uploaded last. Its CID represents the <em>entire file</em>.</li>
</ol>
<h3 id="why-dag-pb"><a class="header" href="#why-dag-pb">Why DAG-PB?</a></h3>
<p>We use the <strong>DAG-PB</strong> (UnixFS) standard used by IPFS. This means:</p>
<ul>
<li>You can retrieve the file from Bulletin Chain using standard IPFS tools if you have the chunks.</li>
<li>The root CID generated by the SDK matches the CID generated by <code>ipfs add</code>.</li>
</ul>
<p>The SDK manages this complexity for you:</p>
<ul>
<li><code>client.prepare_store_chunked</code> (Rust)</li>
<li><code>client.prepareStoreChunked</code> (TS)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="data-retrieval"><a class="header" href="#data-retrieval">Data Retrieval</a></h1>
<p>The Bulletin Chain uses a <strong>write-to-chain, read-from-IPFS</strong> model. Data is stored on-chain via transactions, but retrieval happens through the IPFS network.</p>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h2>
<pre><code>┌─────────────┐     store()      ┌──────────────────┐
│   Your App  │ ───────────────► │  Bulletin Chain  │
└─────────────┘                  └──────────────────┘
       │                                  │
       │                                  │ Bitswap/IPFS
       │                                  ▼
       │   fetch by CID           ┌──────────────────┐
       └─────────────────────────►│   IPFS Gateway   │
                                  └──────────────────┘
</code></pre>
<ol>
<li><strong>Store</strong>: Use the SDK to store data on-chain. You get back a <strong>CID</strong> (Content Identifier).</li>
<li><strong>Retrieve</strong>: Use the CID to fetch data from any IPFS gateway or directly from a Bulletin node running with <code>--ipfs-server</code>.</li>
</ol>
<h2 id="why-this-architecture"><a class="header" href="#why-this-architecture">Why This Architecture?</a></h2>
<ul>
<li><strong>Efficiency</strong>: IPFS is optimized for content distribution; blockchains are optimized for consensus.</li>
<li><strong>Scalability</strong>: Data can be served by any IPFS node, not just Bulletin validators.</li>
<li><strong>Compatibility</strong>: Standard IPFS tools work out of the box.</li>
<li><strong>Availability</strong>: Data remains accessible via IPFS even during chain upgrades.</li>
</ul>
<h2 id="retrieval-methods"><a class="header" href="#retrieval-methods">Retrieval Methods</a></h2>
<h3 id="1-ipfs-http-gateway-recommended"><a class="header" href="#1-ipfs-http-gateway-recommended">1. IPFS HTTP Gateway (Recommended)</a></h3>
<p>The simplest way to retrieve data is through an IPFS HTTP gateway:</p>
<pre><code class="language-javascript">// JavaScript/TypeScript
const cid = "bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi";
const gateway = "https://ipfs.io";

const response = await fetch(`${gateway}/ipfs/${cid}`);
const data = await response.arrayBuffer();
</code></pre>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Rust (using reqwest)
let cid = "bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi";
let gateway = "https://ipfs.io";

let url = format!("{}/ipfs/{}", gateway, cid);
let data = reqwest::get(&amp;url).await?.bytes().await?;
<span class="boring">}</span></code></pre>
<pre><code class="language-bash"># curl
curl "https://ipfs.io/ipfs/bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi"
</code></pre>
<h3 id="2-direct-from-bulletin-node"><a class="header" href="#2-direct-from-bulletin-node">2. Direct from Bulletin Node</a></h3>
<p>If you’re running a Bulletin node with the <code>--ipfs-server</code> flag, you can fetch data directly via Bitswap:</p>
<pre><code class="language-bash"># Start node with IPFS server enabled
./polkadot-bulletin-chain --ipfs-server --chain bulletin-paseo

# The node exposes Bitswap on its libp2p port
# Connect your IPFS client to the node's multiaddr
</code></pre>
<h3 id="3-local-ipfs-node"><a class="header" href="#3-local-ipfs-node">3. Local IPFS Node</a></h3>
<p>If you run a local IPFS node, it can fetch from the Bulletin network:</p>
<pre><code class="language-bash"># Ensure your IPFS node can discover Bulletin nodes (via DHT or direct peering)
ipfs cat bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi
</code></pre>
<h2 id="public-ipfs-gateways"><a class="header" href="#public-ipfs-gateways">Public IPFS Gateways</a></h2>
<p>Here are some public gateways you can use:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Gateway</th><th>URL</th></tr>
</thead>
<tbody>
<tr><td>IPFS.io</td><td><code>https://ipfs.io/ipfs/{cid}</code></td></tr>
<tr><td>Cloudflare</td><td><code>https://cloudflare-ipfs.com/ipfs/{cid}</code></td></tr>
<tr><td>Pinata</td><td><code>https://gateway.pinata.cloud/ipfs/{cid}</code></td></tr>
<tr><td>w3s.link</td><td><code>https://w3s.link/ipfs/{cid}</code></td></tr>
</tbody>
</table>
</div>
<blockquote>
<p><strong>Note</strong>: Public gateways may have rate limits. For production use, consider running your own gateway or using a dedicated service.</p>
</blockquote>
<h2 id="retrieving-chunked-data"><a class="header" href="#retrieving-chunked-data">Retrieving Chunked Data</a></h2>
<p>For large files stored via <code>prepare_store_chunked</code>, the root CID points to a DAG-PB manifest. IPFS gateways automatically reassemble the chunks:</p>
<pre><code class="language-javascript">// The gateway handles reassembly automatically
const rootCid = "bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi";
const response = await fetch(`https://ipfs.io/ipfs/${rootCid}`);
const fullFile = await response.arrayBuffer(); // Reassembled automatically
</code></pre>
<p>If you need to manually retrieve chunks (e.g., for streaming or partial downloads):</p>
<pre><code class="language-javascript">// 1. Fetch the manifest to get chunk CIDs
const manifestResponse = await fetch(`https://ipfs.io/ipfs/${rootCid}?format=dag-json`);
const manifest = await manifestResponse.json();

// 2. Fetch individual chunks
for (const link of manifest.Links) {
    const chunkCid = link.Hash["/"];
    const chunk = await fetch(`https://ipfs.io/ipfs/${chunkCid}`);
    // Process chunk...
}
</code></pre>
<h2 id="complete-example-store-and-retrieve"><a class="header" href="#complete-example-store-and-retrieve">Complete Example: Store and Retrieve</a></h2>
<h3 id="typescript"><a class="header" href="#typescript">TypeScript</a></h3>
<pre><code class="language-typescript">import { BulletinClient, CidCodec, HashAlgorithm } from "@polkadot-bulletin/sdk";

// Store
const client = new BulletinClient();
const data = new TextEncoder().encode("Hello, Bulletin!");
const operation = client.prepareStore(data);
const cidBytes = operation.calculateCid();

// Submit transaction (via PAPI)
// ... submit operation.data to chain ...

// Convert CID bytes to string for retrieval
import { CID } from "multiformats/cid";
const cid = CID.decode(cidBytes);
const cidString = cid.toString();

// Retrieve via gateway
const gateway = "https://ipfs.io";
const response = await fetch(`${gateway}/ipfs/${cidString}`);
const retrieved = new Uint8Array(await response.arrayBuffer());

console.log(new TextDecoder().decode(retrieved)); // "Hello, Bulletin!"
</code></pre>
<h3 id="rust"><a class="header" href="#rust">Rust</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

// Store
let client = BulletinClient::new();
let data = b"Hello, Bulletin!".to_vec();
let operation = client.prepare_store(data, None)?;
let cid_data = operation.calculate_cid()?;
let cid_bytes = cid_data.to_bytes().unwrap();

// Submit transaction (via subxt)
// ... submit operation.data() to chain ...

// Convert CID to string for retrieval
let cid = cid::Cid::try_from(cid_bytes.as_slice())?;
let cid_string = cid.to_string();

// Retrieve via gateway (using reqwest)
let gateway = "https://ipfs.io";
let url = format!("{}/ipfs/{}", gateway, cid_string);
let retrieved = reqwest::get(&amp;url).await?.bytes().await?;

println!("{}", String::from_utf8_lossy(&amp;retrieved)); // "Hello, Bulletin!"
<span class="boring">}</span></code></pre>
<h2 id="data-availability"><a class="header" href="#data-availability">Data Availability</a></h2>
<h3 id="retention-period"><a class="header" href="#retention-period">Retention Period</a></h3>
<p>Data stored on Bulletin Chain is retained for a configurable <strong>retention period</strong> (check chain constants for the current value). After this period:</p>
<ul>
<li>The on-chain transaction data may be pruned</li>
<li>IPFS nodes that have cached the data may still serve it</li>
<li>For long-term availability, consider pinning to a dedicated IPFS pinning service</li>
</ul>
<h3 id="ensuring-availability"><a class="header" href="#ensuring-availability">Ensuring Availability</a></h3>
<p>For critical data, consider:</p>
<ol>
<li><strong>Pinning Services</strong>: Pin your CIDs to services like Pinata, web3.storage, or Filebase</li>
<li><strong>Self-Hosting</strong>: Run your own IPFS node and pin important data</li>
<li><strong>Multiple Gateways</strong>: Don’t rely on a single gateway for retrieval</li>
</ol>
<h2 id="verifying-data-integrity"><a class="header" href="#verifying-data-integrity">Verifying Data Integrity</a></h2>
<p>The CID includes a cryptographic hash of the content. When you retrieve data, you can verify it matches:</p>
<pre><code class="language-typescript">import { CID } from "multiformats/cid";
import { sha256 } from "multiformats/hashes/sha2";

const retrieved = await fetch(`https://ipfs.io/ipfs/${cidString}`);
const data = new Uint8Array(await retrieved.arrayBuffer());

// Recompute hash and verify
const hash = await sha256.digest(data);
const computedCid = CID.create(1, 0x55, hash); // 0x55 = raw codec

if (computedCid.toString() === cidString) {
    console.log("Data integrity verified!");
}
</code></pre>
<h2 id="sdk-roadmap"><a class="header" href="#sdk-roadmap">SDK Roadmap</a></h2>
<blockquote>
<p><strong>Note</strong>: Currently the SDK focuses on storage operations. Retrieval helpers are planned for future releases:</p>
<ul>
<li><code>retrieve(cid, gateway)</code> - Fetch data from IPFS gateway</li>
<li><code>retrieveChunked(cid, gateway)</code> - Stream chunked data</li>
<li><code>verifyIntegrity(cid, data)</code> - Verify data matches CID</li>
</ul>
</blockquote>
<p>For now, use standard HTTP clients or IPFS libraries for retrieval as shown above.</p>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li><a href="#storage-models">Storage Model</a> - Understanding how data is stored</li>
<li><a href="#manifests--ipfs">Manifests &amp; IPFS</a> - DAG-PB format details</li>
<li><a href="#chunked-uploads">Chunked Uploads (Rust)</a> - Storing large files</li>
<li><a href="#chunked-uploads-1">Chunked Uploads (TypeScript)</a> - Storing large files</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="data-renewal"><a class="header" href="#data-renewal">Data Renewal</a></h1>
<p>Data stored on Bulletin Chain has a <strong>retention period</strong> after which it may be pruned from validators. To keep data available on-chain, you must <strong>renew</strong> it before the retention period expires.</p>
<h2 id="the-renewal-flow"><a class="header" href="#the-renewal-flow">The Renewal Flow</a></h2>
<pre><code>1. STORE           2. RECEIVE EVENT      3. TRACK           4. RENEW (later)
   ↓                  ↓                     ↓                  ↓
Submit data    Get block number      Save block/index    Call renew()
to chain       and index from        for later use       before expiration
               Stored event
</code></pre>
<h3 id="step-1-store-data"><a class="header" href="#step-1-store-data">Step 1: Store Data</a></h3>
<p>When you submit a <code>store</code> transaction, data is written to the chain.</p>
<h3 id="step-2-receive-the-stored-event"><a class="header" href="#step-2-receive-the-stored-event">Step 2: Receive the Stored Event</a></h3>
<p>After the transaction is included in a block, the chain emits a <strong>Stored</strong> event containing:</p>
<ul>
<li><code>index</code>: Transaction index within the block</li>
<li><code>content_hash</code>: Hash of the stored content</li>
</ul>
<p>You also need to record the <strong>block number</strong> where the transaction was included.</p>
<h3 id="step-3-track-for-later-renewal"><a class="header" href="#step-3-track-for-later-renewal">Step 3: Track for Later Renewal</a></h3>
<p>Save the <code>(block_number, index)</code> pair. You’ll need these to renew later:</p>
<pre><code>Stored at block 1000, index 5
Retention period: 100,800 blocks
Expires at: block 101,800
</code></pre>
<h3 id="step-4-renew-before-expiration"><a class="header" href="#step-4-renew-before-expiration">Step 4: Renew Before Expiration</a></h3>
<p>Before the retention period ends, submit a <code>renew(block, index)</code> transaction. This:</p>
<ul>
<li>Extends the retention period from the <strong>current block</strong></li>
<li>Emits a new <code>Renewed</code> event with a <strong>new index</strong></li>
<li>You must track the <strong>new</strong> block/index for the next renewal</li>
</ul>
<h2 id="retention-period-1"><a class="header" href="#retention-period-1">Retention Period</a></h2>
<p>The retention period is a chain constant. Query it via:</p>
<ul>
<li>RPC: <code>transactionStorage.retentionPeriod()</code></li>
<li>Typical value: ~100,800 blocks (~7 days at 6s/block)</li>
</ul>
<p>After the retention period, validators may prune the data. The chain no longer guarantees availability.</p>
<h2 id="when-to-renew"><a class="header" href="#when-to-renew">When to Renew</a></h2>
<p><strong>Renew when you need:</strong></p>
<ul>
<li>Guaranteed on-chain availability beyond the retention period</li>
<li>Validators to continue providing storage proofs</li>
<li>Chain-level data guarantees for your application</li>
</ul>
<p><strong>You don’t need to renew if:</strong></p>
<ul>
<li>The data only needs to exist temporarily</li>
<li>You’ve pinned the data to external IPFS nodes</li>
<li>The retention period is sufficient for your use case</li>
</ul>
<h2 id="renewal-chain"><a class="header" href="#renewal-chain">Renewal Chain</a></h2>
<p>Each renewal creates a new record. Always use the <strong>most recent</strong> block and index:</p>
<pre><code>Block 1000: store()  → Stored { index: 5 }
                       ↓
                       Save (1000, 5)
                       ↓
Block 50000: renew(1000, 5) → Renewed { index: 2 }
                              ↓
                              Save (50000, 2)  ← Use this for next renewal!
                              ↓
Block 100000: renew(50000, 2) → Renewed { index: 0 }
                                ↓
                                Save (100000, 0)
</code></pre>
<h2 id="authorization-1"><a class="header" href="#authorization-1">Authorization</a></h2>
<p>Like <code>store</code>, renewal requires <strong>authorization</strong>:</p>
<ul>
<li>The account must have sufficient authorized bytes/transactions</li>
<li>Authorization is consumed based on the data size</li>
<li>Pre-authorize enough capacity if you plan multiple renewals</li>
</ul>
<h2 id="ipfs-availability"><a class="header" href="#ipfs-availability">IPFS Availability</a></h2>
<p>Even after data expires on-chain:</p>
<ul>
<li>IPFS nodes that cached the data may still serve it</li>
<li>Pinning services can maintain availability indefinitely</li>
<li>The CID remains valid; only on-chain guarantees expire</li>
</ul>
<p>For critical data, consider both renewal AND external IPFS pinning.</p>
<h2 id="sdk-support"><a class="header" href="#sdk-support">SDK Support</a></h2>
<p>Both SDKs provide renewal helpers:</p>
<ul>
<li><strong>Rust SDK</strong>: <code>prepare_renew()</code>, <code>RenewalTracker</code> - See <a href="#renewal">Rust SDK: Renewal</a></li>
<li><strong>TypeScript SDK</strong>: Coming soon - See <a href="typescript/README.html">TypeScript SDK</a></li>
</ul>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<ul>
<li><a href="#renewal">Rust SDK: Renewal</a> - SDK-specific implementation</li>
<li><a href="#storage-models">Storage Model</a> - How data is stored</li>
<li><a href="#data-retrieval">Data Retrieval</a> - Fetching via IPFS</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="manifests--ipfs"><a class="header" href="#manifests--ipfs">Manifests &amp; IPFS</a></h1>
<h2 id="what-is-a-manifest"><a class="header" href="#what-is-a-manifest">What is a Manifest?</a></h2>
<p>In the context of the SDK, a <strong>Manifest</strong> is a small data structure that describes how to reassemble a large file from its chunks. We use <a href="https://docs.ipfs.tech/concepts/merkle-dag/"><strong>DAG-PB</strong></a> (Merkle DAG Protobuf), which is the default format for IPFS.</p>
<p>When you upload a large file using the SDK:</p>
<ol>
<li>The file is split into chunks (leaves).</li>
<li>Each chunk is hashed and uploaded.</li>
<li>A “Root Node” (the manifest) is created. It contains:
<ul>
<li><code>Links</code>: A list of CIDs pointing to the chunks.</li>
<li><code>Data</code>: UnixFS metadata (file size, type).</li>
</ul>
</li>
</ol>
<h2 id="ipfs-compatibility"><a class="header" href="#ipfs-compatibility">IPFS Compatibility</a></h2>
<p>Because we use standard DAG-PB:</p>
<ul>
<li>The <strong>Root CID</strong> generated by the SDK is identical to the CID generated by running <code>ipfs add --chunker=size-1048576 file.bin</code>.</li>
<li>If you run an IPFS node and pin the chunks, the file becomes available on the public IPFS network.</li>
<li>Bulletin Chain acts as the “ledger of record” for these CIDs.</li>
</ul>
<h2 id="manifest-structure"><a class="header" href="#manifest-structure">Manifest Structure</a></h2>
<p>A simplified view of a manifest node:</p>
<pre><code class="language-protobuf">message PBNode {
  repeated PBLink Links = 2;
  optional bytes Data = 1;
}

message PBLink {
  optional bytes Hash = 1; // CID of the chunk
  optional string Name = 2;
  optional uint64 Tsize = 3; // Size of the chunk
}
</code></pre>
<p>The SDKs include a <code>DagBuilder</code> (Rust) or <code>UnixFsDagBuilder</code> (TS) that constructs this binary format for you.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="rust-sdk"><a class="header" href="#rust-sdk">Rust SDK</a></h1>
<p>The <code>bulletin-sdk-rust</code> crate provides a robust client for interacting with the Bulletin Chain. It is designed to be:</p>
<ul>
<li><strong>Type-Safe</strong>: Leverages Rust’s type system to prevent common errors.</li>
<li><strong>Flexible</strong>: Works with <code>std</code> (standard library) and <code>no_std</code> (WASM/embedded) environments.</li>
<li><strong>Modular</strong>: Use only what you need (chunking, CID calculation, or full client).</li>
</ul>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<ul>
<li><strong>Direct subxt Integration</strong>: Tightly coupled to <code>subxt</code> for type-safe blockchain interaction</li>
<li><strong>Flexible Architecture</strong>: Use <code>AsyncBulletinClient</code> for full automation or <code>BulletinClient</code> for manual preparation</li>
<li><strong>Builder Pattern</strong>: Fluent API for configuring store operations</li>
<li><strong>Mock Testing</strong>: <code>MockBulletinClient</code> allows testing without a blockchain node</li>
<li><strong>Runtime Metadata</strong>: Users configure subxt with their own metadata for maximum flexibility</li>
</ul>
<h2 id="modules"><a class="header" href="#modules">Modules</a></h2>
<ul>
<li><code>async_client</code>: High-level async client with transaction submission (<code>AsyncBulletinClient</code>)</li>
<li><code>mock_client</code>: Mock client for testing without blockchain (<code>MockBulletinClient</code>)</li>
<li><code>client</code>: Core client for operation preparation (<code>BulletinClient</code>)</li>
<li><code>chunker</code>: Splits data into chunks (<code>FixedSizeChunker</code>)</li>
<li><code>cid</code>: CID calculation utilities</li>
<li><code>storage</code>: Transaction preparation helpers</li>
<li><code>authorization</code>: Authorization management</li>
</ul>
<h2 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;
use subxt::{OnlineClient, PolkadotConfig};
use subxt_signer::sr25519::dev;

let ws_url = std::env::var("BULLETIN_WS_URL")
    .unwrap_or_else(|_| "ws://localhost:10000".to_string());

// Initialize signer from dev account (for testing)
// In production, use: Keypair::from_phrase() with your seed phrase
let signer = dev::alice();

// Connect to the blockchain using subxt
// Users must configure subxt with their own runtime metadata
let api = OnlineClient::&lt;PolkadotConfig&gt;::from_url(&amp;ws_url).await?;

// Create SDK client with subxt client
let client = AsyncBulletinClient::new(api);

// Store data using builder pattern
let result = client
    .store(data)
    .send()
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="using-multiple-accounts"><a class="header" href="#using-multiple-accounts">Using Multiple Accounts</a></h3>
<p>If you need to use different accounts, you need to handle signing at the transaction level.
The SDK client uses subxt directly, so you control the signer when creating transactions.</p>
<p>For testing without a blockchain, use the <code>MockBulletinClient</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

// Create mock client (no blockchain required)
let client = MockBulletinClient::new();

// Store data - calculates real CIDs but doesn't submit to chain
let result = client.store(data).send().await?;

// Verify operations performed
let ops = client.operations();
assert_eq!(ops.len(), 1);
<span class="boring">}</span></code></pre>
<h3 id="production-signer-setup"><a class="header" href="#production-signer-setup">Production Signer Setup</a></h3>
<p>For production, use a seed phrase or private key:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use subxt_signer::sr25519::Keypair;

// From mnemonic seed phrase
let signer = Keypair::from_phrase(
    "bottom drive obey lake curtain smoke basket hold race lonely fit walk",
    None, // password
).expect("Invalid seed phrase");

// From secret URI (like //Alice for dev)
let signer = Keypair::from_uri("//Alice")
    .expect("Invalid URI");

let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
let client = AsyncBulletinClient::new(submitter);
<span class="boring">}</span></code></pre>
<p>Proceed to <a href="#installation">Installation</a> to get started.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>Add the SDK to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
bulletin-sdk-rust = "0.1"
</code></pre>
<h2 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h2>
<p>The SDK exposes several feature flags to optimize your build:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Feature</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>std</code></td><td>Yes</td><td>Enables standard library support. Disable for <code>no_std</code>.</td></tr>
<tr><td><code>serde-support</code></td><td>No</td><td>Adds <code>Serialize</code>/<code>Deserialize</code> support for types.</td></tr>
</tbody>
</table>
</div>
<h2 id="transaction-submission"><a class="header" href="#transaction-submission">Transaction Submission</a></h2>
<p>The SDK provides data preparation and CID calculation utilities. To submit transactions to the blockchain, you’ll use <code>subxt</code> for blockchain interaction.</p>
<p>Add <code>subxt</code> to your dependencies:</p>
<pre><code class="language-toml">[dependencies]
bulletin-sdk-rust = "0.1"
subxt = "0.44"
tokio = { version = "1", features = ["full"] }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="authorization-2"><a class="header" href="#authorization-2">Authorization</a></h1>
<h2 id="quick-authorization-recommended"><a class="header" href="#quick-authorization-recommended">Quick Authorization (Recommended)</a></h2>
<p>For most use cases, use <code>estimate_authorization</code> to automatically calculate the required authorization:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;
use tracing::info;

let client = BulletinClient::new();
let file_size = 100 * 1024 * 1024; // 100 MiB

// Automatically calculates transactions and bytes needed
let (txs, bytes) = client.estimate_authorization(file_size);
info!(transactions = txs, bytes = bytes, "Authorization needed");
<span class="boring">}</span></code></pre>
<blockquote>
<p><strong>Convenience Note</strong>: The estimation is automatic - you just provide the file size, and it calculates chunking, manifest overhead, etc. A future enhancement could provide <code>authorize_for_size(account, size)</code> that combines estimation and authorization submission into one call.</p>
</blockquote>
<p>Then submit the authorization transaction:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tx = bulletin::tx().transaction_storage().authorize_account(
    target_account,
    txs,
    bytes
);
<span class="boring">}</span></code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="basic-storage"><a class="header" href="#basic-storage">Basic Storage</a></h1>
<p>This guide shows how to store data using the <code>AsyncBulletinClient</code> with transaction submitters.</p>
<blockquote>
<p><strong>Note on Logging</strong>: All examples use <code>tracing</code> for structured logging. If you’re integrating with Substrate runtime/node code, you can use <code>sp_tracing</code> instead for better compatibility with Substrate’s logging infrastructure.</p>
</blockquote>
<h2 id="quick-start-2"><a class="header" href="#quick-start-2">Quick Start</a></h2>
<p>The <code>store()</code> method uses a builder pattern for a clean, fluent API:</p>
<h3 id="why-builder-pattern"><a class="header" href="#why-builder-pattern">Why Builder Pattern?</a></h3>
<p>The builder pattern provides:</p>
<ul>
<li><strong>Fluent API</strong>: Chain methods for clean, readable code</li>
<li><strong>Type safety</strong>: Compile-time validation of options</li>
<li><strong>Discoverability</strong>: IDE autocomplete shows all available options</li>
<li><strong>Flexibility</strong>: Only specify options you need</li>
<li><strong>Clarity</strong>: Intent is clear from method names</li>
</ul>
<h3 id="basic-example"><a class="header" href="#basic-example">Basic Example</a></h3>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;
use tracing::info;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Initialize tracing subscriber for logging
    tracing_subscriber::fmt::init();

    // 1. Connect to Bulletin Chain
    // Available endpoints (see shared/networks.ts for full list):
    //   - Local:    ws://localhost:10000
    //   - Westend:  wss://westend-bulletin-rpc.polkadot.io
    //   - Paseo:    wss://paseo-bulletin-rpc.polkadot.io
    //   - Dotspark: wss://bulletin.dotspark.app
    let ws_url = std::env::var("BULLETIN_WS_URL")
        .unwrap_or_else(|_| "wss://paseo-bulletin-rpc.polkadot.io".to_string());
    let signer = /* your PairSigner */;

    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter);

    // 2. Prepare and store data with builder pattern
    let data = b"Hello, Bulletin!".to_vec();
    let result = client
        .store(data)
        .send()
        .await?;

    // 3. Get results
    info!("Stored successfully!");
    info!(cid = %hex::encode(&amp;result.cid), size = result.size, "Storage complete");

    Ok(())
}</code></pre>
<h2 id="step-by-step-explanation"><a class="header" href="#step-by-step-explanation">Step-by-Step Explanation</a></h2>
<h3 id="1-setup-connection"><a class="header" href="#1-setup-connection">1. Setup Connection</a></h3>
<p>First, create a transaction submitter. The submitter handles all blockchain communication:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

// Option 1: From URL (recommended)
let ws_url = "ws://localhost:10000";
let submitter = SubxtSubmitter::from_url(ws_url, signer).await?;

// Option 2: For testing without a node
let submitter = MockSubmitter::new();
<span class="boring">}</span></code></pre>
<p>Learn more about submitters in the <a href="rust/submitters.html">Transaction Submitters</a> guide.</p>
<h3 id="2-create-client"><a class="header" href="#2-create-client">2. Create Client</a></h3>
<p>Wrap the submitter with <code>AsyncBulletinClient</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let client = AsyncBulletinClient::new(submitter);
<span class="boring">}</span></code></pre>
<h3 id="3-prepare-data"><a class="header" href="#3-prepare-data">3. Prepare Data</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let data = b"Hello, Bulletin!".to_vec();
<span class="boring">}</span></code></pre>
<h3 id="4-store-with-builder-pattern"><a class="header" href="#4-store-with-builder-pattern">4. Store with Builder Pattern</a></h3>
<p>The <code>store()</code> method returns a builder for fluent configuration:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simple storage with defaults
let result = client
    .store(data)
    .send()
    .await?;

// Customize CID codec
let result = client
    .store(data)
    .with_codec(CidCodec::DagPb)
    .send()
    .await?;

// Customize hash algorithm
let result = client
    .store(data)
    .with_hash_algorithm(HashAlgorithm::Sha256)
    .send()
    .await?;

// Combine multiple options
let result = client
    .store(data)
    .with_codec(CidCodec::DagCbor)
    .with_hash_algorithm(HashAlgorithm::Blake2b256)
    .with_finalization(true)
    .send()
    .await?;

// With progress callback for chunked uploads
let result = client
    .store(large_data)
    .with_callback(|event| {
        tracing::debug!(?event, "Upload progress");
    })
    .send()
    .await?;
<span class="boring">}</span></code></pre>
<p>The builder automatically handles:</p>
<ul>
<li>Data validation</li>
<li>Authorization checks (if configured)</li>
<li>Automatic chunking for large files (&gt; 2 MiB by default)</li>
<li>CID calculation</li>
<li>Transaction submission</li>
<li>Finalization wait</li>
</ul>
<h3 id="5-handle-result"><a class="header" href="#5-handle-result">5. Handle Result</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>tracing::info!(
    cid = %hex::encode(&amp;result.cid),
    size = result.size,
    block = ?result.block_number,
    "Storage successful"
);
<span class="boring">}</span></code></pre>
<h2 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h2>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;
use std::env;
use tracing::info;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Initialize tracing subscriber
    tracing_subscriber::fmt::init();

    // Get WebSocket URL from environment or CLI
    let ws_url = env::var("BULLETIN_WS_URL")
        .unwrap_or_else(|_| "ws://localhost:10000".to_string());

    // Create signer (use your actual signer)
    let signer = /* your PairSigner from keypair */;

    // Connect and create client
    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter);

    // Store data with builder pattern
    let data = format!("Hello from Rust SDK at {}", chrono::Utc::now());
    let result = client
        .store(data.as_bytes().to_vec())
        .send()
        .await?;

    info!(
        cid = %hex::encode(&amp;result.cid),
        size = result.size,
        "Stored successfully"
    );

    Ok(())
}</code></pre>
<h2 id="authorization-checking-fail-fast"><a class="header" href="#authorization-checking-fail-fast">Authorization Checking (Fail Fast)</a></h2>
<p>By default, the SDK checks authorization <strong>before</strong> uploading to fail fast and avoid wasted transaction fees.</p>
<h3 id="how-it-works-1"><a class="header" href="#how-it-works-1">How It Works</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

// 1. Create client with your account
let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;

// Note: In most cases, you can get the account from your signer/keypair.
// We pass it separately to support advanced scenarios (multisig, delegated auth, etc.)
let account = signer.account_id(); // Or AccountId32::from(keypair.public())

let client = AsyncBulletinClient::new(submitter)
    .with_account(account);  // Enable automatic authorization checking

// 2. Upload - authorization is checked automatically
let data = b"Hello, Bulletin!".to_vec();
let result = client
    .store(data)
    .send()
    .await?;
//  ⬆️ Queries blockchain first, fails fast if insufficient auth
<span class="boring">}</span></code></pre>
<h3 id="what-gets-checked"><a class="header" href="#what-gets-checked">What Gets Checked</a></h3>
<p>Before submitting the transaction, the SDK:</p>
<ol>
<li><strong>Queries</strong> the blockchain for your current authorization</li>
<li><strong>Validates</strong> you have enough transactions and bytes authorized</li>
<li><strong>Fails immediately</strong> if insufficient (no transaction fees wasted!)</li>
<li><strong>Proceeds</strong> only if authorization is sufficient</li>
</ol>
<h3 id="disable-authorization-checking-advanced"><a class="header" href="#disable-authorization-checking-advanced">Disable Authorization Checking (Advanced)</a></h3>
<blockquote>
<p><strong>Note</strong>: Authorization checking is enabled by default and is recommended for most use cases. It prevents wasted transaction fees by failing early if you lack authorization.</p>
</blockquote>
<p>In rare scenarios, you might want to skip pre-flight authorization checking:</p>
<ul>
<li><strong>High-frequency uploads</strong>: When uploading many small files sequentially and the query overhead matters (&lt; 100ms per upload). You’ve already verified authorization manually and trust it’s sufficient.</li>
<li><strong>Testing</strong>: When you specifically want to test on-chain authorization validation errors.</li>
<li><strong>Offline signing</strong>: When preparing transactions offline for later broadcast where the blockchain isn’t accessible.</li>
</ul>
<p><strong>Trade-off</strong>: Disabling the check saves ~100ms per upload but risks submitting transactions that fail on-chain (wasting transaction fees).</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::async_client::AsyncClientConfig;

let mut config = AsyncClientConfig::default();
config.check_authorization_before_upload = false;  // Disable pre-flight checking

let client = AsyncBulletinClient::with_config(submitter, config)
    .with_account(account);

// Authorization will still be validated on-chain during transaction execution
<span class="boring">}</span></code></pre>
<h3 id="error-example"><a class="header" href="#error-example">Error Example</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Insufficient authorization fails fast
match client.store(data).send().await {
    Err(Error::InsufficientAuthorization { need, available }) =&gt; {
        tracing::error!(
            need_bytes = need,
            available_bytes = available,
            "Insufficient authorization - please authorize your account first"
        );
    }
    Ok(result) =&gt; {
        tracing::info!("Storage successful");
    }
    Err(e) =&gt; {
        tracing::error!(?e, "Storage failed");
    }
}
<span class="boring">}</span></code></pre>
<h3 id="complete-example-with-authorization"><a class="header" href="#complete-example-with-authorization">Complete Example with Authorization</a></h3>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;
use tracing::{info, error};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Initialize tracing
    tracing_subscriber::fmt::init();

    let ws_url = std::env::var("BULLETIN_WS_URL")
        .unwrap_or_else(|_| "ws://localhost:10000".to_string());
    let signer = /* your signer */;
    let account = /* your AccountId32 */;

    // Connect
    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter)
        .with_account(account.clone());

    // Estimate what's needed
    let data = std::fs::read("myfile.dat")?;
    let (txs, bytes) = client.estimate_authorization(data.len() as u64);
    info!(transactions = txs, bytes = bytes, "Authorization needed");

    // Authorize (if needed)
    // client.authorize_account(account, txs, bytes).await?;

    // Store - will check authorization automatically
    match client.store(data).send().await {
        Ok(result) =&gt; {
            info!(cid = %hex::encode(&amp;result.cid), "Stored successfully");
        }
        Err(Error::InsufficientAuthorization { need, available }) =&gt; {
            error!(
                need_bytes = need,
                available_bytes = available,
                "Insufficient authorization - please authorize your account first"
            );
            return Err("Please authorize your account first".into());
        }
        Err(e) =&gt; {
            error!(?e, "Storage failed");
            return Err(e.into());
        }
    }

    Ok(())
}</code></pre>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match client.store(data).send().await {
    Ok(result) =&gt; {
        tracing::info!(cid = %hex::encode(&amp;result.cid), "Storage successful");
    }
    Err(Error::EmptyData) =&gt; {
        tracing::error!("Cannot store empty data");
    }
    Err(Error::SubmissionFailed(msg)) =&gt; {
        tracing::error!(reason = %msg, "Submission failed");
    }
    Err(e) =&gt; {
        tracing::error!(?e, "Unexpected error");
    }
}
<span class="boring">}</span></code></pre>
<h2 id="testing-without-a-node"><a class="header" href="#testing-without-a-node">Testing Without a Node</a></h2>
<p>Use <code>MockSubmitter</code> for unit tests:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    use bulletin_sdk_rust::prelude::*;

    #[tokio::test]
    async fn test_store() {
        let submitter = MockSubmitter::new();
        let client = AsyncBulletinClient::new(submitter);

        let data = b"test data".to_vec();
        let result = client.store(data, None).await;

        assert!(result.is_ok());
    }
}
<span class="boring">}</span></code></pre>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ul>
<li><a href="#chunked-uploads">Chunked Uploads</a> - For files &gt; 8 MiB</li>
<li><a href="#authorization-2">Authorization</a> - Managing storage authorization</li>
<li><a href="rust/submitters.html">Transaction Submitters</a> - Deep dive into submitters</li>
</ul>
<h2 id="two-step-approach-advanced"><a class="header" href="#two-step-approach-advanced">Two-Step Approach (Advanced)</a></h2>
<p>If you need more control, use the two-step approach:</p>
<h3 id="step-1-prepare-operation"><a class="header" href="#step-1-prepare-operation">Step 1: Prepare Operation</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::client::BulletinClient;
use tracing::info;

let client = BulletinClient::new();
let operation = client.prepare_store(data, options)?;

info!(
    cid = %hex::encode(&amp;operation.cid_bytes),
    size = operation.data.len(),
    "Prepared store operation"
);
<span class="boring">}</span></code></pre>
<h3 id="step-2-submit-manually"><a class="header" href="#step-2-submit-manually">Step 2: Submit Manually</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Submit using your own method
let receipt = submitter.submit_store(operation.data).await?;
<span class="boring">}</span></code></pre>
<p>This is useful when:</p>
<ul>
<li>You need the CID before submission</li>
<li>You’re batching multiple operations</li>
<li>You’re using a custom submission method</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chunked-uploads"><a class="header" href="#chunked-uploads">Chunked Uploads</a></h1>
<p>The Bulletin SDK automatically handles chunking for large files. When you call <code>store()</code>, files larger than the threshold (default 2 MiB) are automatically split into chunks.</p>
<h2 id="automatic-chunking-recommended"><a class="header" href="#automatic-chunking-recommended">Automatic Chunking (Recommended)</a></h2>
<p>For most use cases, simply use <code>store()</code> - it automatically chunks large files:</p>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter);

    // Load file of any size
    let data = std::fs::read("any-size-file.bin")?;

    // Automatically chunks if &gt; 2 MiB
    let result = client
        .store(data)
        .with_callback(|event| {
            match event {
                ProgressEvent::ChunkCompleted { index, total, .. } =&gt; {
                    tracing::info!(chunk = index + 1, total = total, "Chunk uploaded");
                }
                ProgressEvent::Completed { .. } =&gt; {
                    tracing::info!("Upload complete");
                }
                _ =&gt; {}
            }
        })
        .send()
        .await?;

    tracing::info!(cid = %hex::encode(&amp;result.cid), "Stored successfully");
    if let Some(chunks) = result.chunks {
        tracing::info!(num_chunks = chunks.num_chunks, "File was chunked");
    }

    Ok(())
}</code></pre>
<blockquote>
<p><strong>Convenience Note</strong>: Currently you need to provide your own progress callback. A future enhancement could provide a default progress handler like <code>.with_default_progress()</code> that automatically logs to tracing, so you don’t need to write the match statement every time.</p>
</blockquote>
<h3 id="configuring-automatic-chunking"><a class="header" href="#configuring-automatic-chunking">Configuring Automatic Chunking</a></h3>
<p>You can configure the threshold and chunk size:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::async_client::AsyncClientConfig;

let config = AsyncClientConfig {
    chunking_threshold: 5 * 1024 * 1024,  // Chunk files &gt; 5 MiB
    default_chunk_size: 2 * 1024 * 1024,   // 2 MiB chunks
    max_parallel: 8,                        // Upload 8 chunks in parallel
    create_manifest: true,                  // Create DAG-PB manifest
    check_authorization_before_upload: true,
};

let client = AsyncBulletinClient::with_config(submitter, config);
<span class="boring">}</span></code></pre>
<h2 id="advanced-manual-chunking"><a class="header" href="#advanced-manual-chunking">Advanced: Manual Chunking</a></h2>
<p>For advanced use cases where you need explicit control over chunking parameters, use <code>store_chunked()</code>:</p>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Setup client (see Basic Storage guide)
    let ws_url = std::env::var("BULLETIN_WS_URL")
        .unwrap_or_else(|_| "ws://localhost:10000".to_string());
    let signer = /* your PairSigner */;

    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter);

    // Load large file
    let large_data = std::fs::read("large-file.bin")?;
    println!("File size: {} bytes", large_data.len());

    // Configure chunking explicitly
    let config = ChunkerConfig {
        chunk_size: 1024 * 1024,  // 1 MiB chunks
        max_parallel: 8,           // Upload 8 chunks in parallel
        create_manifest: true,     // Create DAG-PB manifest
    };

    // Optional: track progress
    let progress_callback = |event: ProgressEvent| {
        match event {
            ProgressEvent::ChunkStarted { index, total } =&gt; {
                println!("Uploading chunk {}/{}", index + 1, total);
            }
            ProgressEvent::ChunkCompleted { index, total, cid } =&gt; {
                println!("✓ Chunk {}/{} complete: {}", index + 1, total, hex::encode(cid));
            }
            ProgressEvent::ChunkFailed { index, total, error } =&gt; {
                eprintln!("✗ Chunk {}/{} failed: {}", index + 1, total, error);
            }
            ProgressEvent::ManifestCreated { cid } =&gt; {
                println!("📦 Manifest created: {}", hex::encode(cid));
            }
            ProgressEvent::Completed { manifest_cid } =&gt; {
                if let Some(cid) = manifest_cid {
                    println!("✅ All done! Manifest CID: {}", hex::encode(cid));
                }
            }
            _ =&gt; {}
        }
    };

    // Upload with manual chunking configuration and progress tracking
    let result = client
        .store_chunked(
            &amp;large_data,
            Some(config),
            StoreOptions::default(),
            Some(progress_callback),
        )
        .await?;

    println!("\n📊 Upload Summary:");
    println!("   Total size: {} bytes", result.total_size);
    println!("   Chunks: {}", result.num_chunks);
    println!("   Chunk CIDs: {} items", result.chunk_cids.len());
    if let Some(manifest_cid) = result.manifest_cid {
        println!("   Manifest CID: {}", hex::encode(manifest_cid));
    }

    Ok(())
}</code></pre>
<h2 id="how-it-works-2"><a class="header" href="#how-it-works-2">How It Works</a></h2>
<p>The <code>store_chunked()</code> method:</p>
<ol>
<li><strong>Splits data</strong> into chunks (default 1 MiB)</li>
<li><strong>Calculates CIDs</strong> for each chunk</li>
<li><strong>Submits chunks</strong> sequentially or in parallel</li>
<li><strong>Creates DAG-PB manifest</strong> linking all chunks</li>
<li><strong>Submits manifest</strong> as final transaction</li>
<li><strong>Returns result</strong> with all CIDs</li>
</ol>
<h3 id="when-to-use-store_chunked-vs-store"><a class="header" href="#when-to-use-store_chunked-vs-store">When to Use <code>store_chunked()</code> vs <code>store()</code></a></h3>
<p><strong>Use <code>store()</code> (recommended):</strong></p>
<ul>
<li>✅ For most use cases - it automatically handles everything</li>
<li>✅ When you don’t need detailed chunk information</li>
<li>✅ For both small and large files</li>
</ul>
<p><strong>Use <code>store_chunked()</code> (advanced):</strong></p>
<ul>
<li>⚙️ When you need detailed control over chunking parameters</li>
<li>⚙️ When you need the full <code>ChunkedStoreResult</code> with all chunk CIDs</li>
<li>⚙️ When you want to force chunking on small files</li>
<li>⚙️ For testing or debugging chunking behavior</li>
</ul>
<p><strong>Key Difference:</strong></p>
<ul>
<li><code>store()</code> returns <code>StoreResult</code> with optional chunk info</li>
<li><code>store_chunked()</code> returns <code>ChunkedStoreResult</code> with detailed chunk information</li>
</ul>
<h2 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h2>
<h3 id="chunk-size"><a class="header" href="#chunk-size">Chunk Size</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = ChunkerConfig {
    chunk_size: 2 * 1024 * 1024,  // 2 MiB chunks (max is 2 MiB for Bitswap)
    max_parallel: 4,
    create_manifest: true,
};
<span class="boring">}</span></code></pre>
<p><strong>Guidelines:</strong></p>
<ul>
<li>Minimum: 1 MiB (1,048,576 bytes)</li>
<li>Maximum: 2 MiB (2,097,152 bytes) - Bitswap compatibility limit</li>
<li>Default: 1 MiB - good balance of efficiency and compatibility</li>
</ul>
<h3 id="parallel-uploads"><a class="header" href="#parallel-uploads">Parallel Uploads</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = ChunkerConfig {
    chunk_size: 1024 * 1024,
    max_parallel: 8,  // Upload up to 8 chunks simultaneously
    create_manifest: true,
};
<span class="boring">}</span></code></pre>
<p><strong>Note</strong>: Current implementation uploads sequentially. Parallel support is planned for a future release.</p>
<h3 id="manifest-creation"><a class="header" href="#manifest-creation">Manifest Creation</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// With manifest (IPFS-compatible, recommended)
let config = ChunkerConfig {
    chunk_size: 1024 * 1024,
    max_parallel: 8,
    create_manifest: true,  // Creates DAG-PB manifest
};

// Without manifest (just upload chunks)
let config = ChunkerConfig {
    chunk_size: 1024 * 1024,
    max_parallel: 8,
    create_manifest: false,  // No manifest, just chunks
};
<span class="boring">}</span></code></pre>
<h2 id="progress-tracking"><a class="header" href="#progress-tracking">Progress Tracking</a></h2>
<p>Track upload progress with callbacks:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let progress = |event: ProgressEvent| {
    match event {
        ProgressEvent::ChunkStarted { index, total } =&gt; {
            println!("[{}/{}] Starting chunk...", index + 1, total);
        }
        ProgressEvent::ChunkCompleted { index, total, cid } =&gt; {
            println!("[{}/{}] ✓ Uploaded: {}", index + 1, total, hex::encode(cid));
        }
        ProgressEvent::ChunkFailed { index, total, error } =&gt; {
            eprintln!("[{}/{}] ✗ Failed: {}", index + 1, total, error);
        }
        ProgressEvent::ManifestStarted =&gt; {
            println!("Creating manifest...");
        }
        ProgressEvent::ManifestCreated { cid } =&gt; {
            println!("Manifest CID: {}", hex::encode(cid));
        }
        ProgressEvent::Completed { manifest_cid } =&gt; {
            println!("Upload complete!");
        }
    }
};

let result = client
    .store_chunked(&amp;data, Some(config), options, Some(progress))
    .await?;
<span class="boring">}</span></code></pre>
<h2 id="result-structure"><a class="header" href="#result-structure">Result Structure</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ChunkedStoreResult {
    pub chunk_cids: Vec&lt;Vec&lt;u8&gt;&gt;,    // CID for each chunk
    pub manifest_cid: Option&lt;Vec&lt;u8&gt;&gt;, // CID of the DAG-PB manifest
    pub total_size: u64,              // Total bytes uploaded
    pub num_chunks: u32,              // Number of chunks
}
<span class="boring">}</span></code></pre>
<p>Access results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let result = client.store_chunked(&amp;data, config, options, None).await?;

println!("Uploaded {} chunks", result.num_chunks);
println!("Total: {} bytes", result.total_size);

// Print all chunk CIDs
for (i, cid) in result.chunk_cids.iter().enumerate() {
    println!("Chunk {}: {}", i, hex::encode(cid));
}

// Use manifest CID for retrieval
if let Some(manifest_cid) = result.manifest_cid {
    println!("Retrieve via: {}", hex::encode(manifest_cid));
}
<span class="boring">}</span></code></pre>
<h2 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match client.store_chunked(&amp;data, config, options, progress).await {
    Ok(result) =&gt; {
        println!("Success! {} chunks uploaded", result.num_chunks);
    }
    Err(Error::EmptyData) =&gt; {
        eprintln!("Error: No data to upload");
    }
    Err(Error::ChunkTooLarge(size)) =&gt; {
        eprintln!("Error: Chunk size {} exceeds limit", size);
    }
    Err(Error::SubmissionFailed(msg)) =&gt; {
        eprintln!("Upload failed: {}", msg);
    }
    Err(e) =&gt; {
        eprintln!("Unexpected error: {:?}", e);
    }
}
<span class="boring">}</span></code></pre>
<h2 id="testing-chunked-uploads"><a class="header" href="#testing-chunked-uploads">Testing Chunked Uploads</a></h2>
<p>Use <code>MockSubmitter</code> for testing:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    use bulletin_sdk_rust::prelude::*;

    #[tokio::test]
    async fn test_chunked_upload() {
        let submitter = MockSubmitter::new();
        let client = AsyncBulletinClient::new(submitter);

        // Create 10 MB test data
        let data = vec![0u8; 10 * 1024 * 1024];

        let config = ChunkerConfig {
            chunk_size: 1024 * 1024,
            max_parallel: 8,
            create_manifest: true,
        };

        let result = client
            .store_chunked(&amp;data, Some(config), StoreOptions::default(), None)
            .await
            .unwrap();

        assert_eq!(result.num_chunks, 10);
        assert_eq!(result.chunk_cids.len(), 10);
        assert!(result.manifest_cid.is_some());
    }
}
<span class="boring">}</span></code></pre>
<h2 id="complete-example-1"><a class="header" href="#complete-example-1">Complete Example</a></h2>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;
use std::path::Path;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Setup
    let ws_url = std::env::var("BULLETIN_WS_URL")
        .unwrap_or_else(|_| "ws://localhost:10000".to_string());
    let signer = /* your signer */;

    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter);

    // Load file
    let file_path = Path::new("large-video.mp4");
    let data = std::fs::read(file_path)?;
    println!("Uploading {} ({} bytes)", file_path.display(), data.len());

    // Configure
    let config = ChunkerConfig {
        chunk_size: 1024 * 1024,  // 1 MiB
        max_parallel: 8,
        create_manifest: true,
    };

    // Upload with progress
    let start = std::time::Instant::now();

    let result = client
        .store_chunked(
            &amp;data,
            Some(config),
            StoreOptions::default(),
            Some(|event| {
                if let ProgressEvent::ChunkCompleted { index, total, .. } = event {
                    let percent = ((index + 1) as f64 / total as f64) * 100.0;
                    print!("\rProgress: {:.1}%", percent);
                    std::io::Write::flush(&amp;mut std::io::stdout()).ok();
                }
            }),
        )
        .await?;

    let duration = start.elapsed();
    println!("\n\n✅ Upload complete in {:.2}s", duration.as_secs_f64());
    println!("   Manifest CID: {}", hex::encode(result.manifest_cid.unwrap()));
    println!("   {} chunks uploaded", result.num_chunks);

    Ok(())
}</code></pre>
<h2 id="two-step-approach-advanced-1"><a class="header" href="#two-step-approach-advanced-1">Two-Step Approach (Advanced)</a></h2>
<p>For more control, prepare chunks separately:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::client::BulletinClient;

// Step 1: Prepare chunks locally
let client = BulletinClient::new();
let (batch, manifest_data) = client.prepare_store_chunked(
    &amp;data,
    Some(config),
    StoreOptions::default(),
    Some(progress),
)?;

// Step 2: Submit manually
for operation in batch.operations {
    // Submit operation.data with your own method
    let receipt = custom_submit(operation.data).await?;
}

if let Some(manifest_bytes) = manifest_data {
    let receipt = custom_submit(manifest_bytes).await?;
}
<span class="boring">}</span></code></pre>
<h2 id="authorization-checking-fail-fast-1"><a class="header" href="#authorization-checking-fail-fast-1">Authorization Checking (Fail Fast)</a></h2>
<p>For large chunked uploads, authorization checking is especially important to avoid wasting time uploading many chunks only to fail at the end.</p>
<h3 id="automatic-checking"><a class="header" href="#automatic-checking">Automatic Checking</a></h3>
<p>By default, the SDK checks authorization before starting any chunk uploads:</p>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let ws_url = std::env::var("BULLETIN_WS_URL")
        .unwrap_or_else(|_| "ws://localhost:10000".to_string());
    let signer = /* your signer */;
    let account = /* your AccountId32 */;

    // Create client with account for authorization checking
    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter)
        .with_account(account);

    // Load large file
    let data = std::fs::read("large-file.bin")?;
    println!("File size: {} bytes", data.len());

    // Configure chunking
    let config = ChunkerConfig {
        chunk_size: 1024 * 1024,  // 1 MiB
        max_parallel: 8,
        create_manifest: true,
    };

    // Upload - authorization is checked BEFORE uploading any chunks
    let result = client
        .store_chunked(&amp;data, Some(config), StoreOptions::default(), None)
        .await?;
    //           ⬆️ Fails immediately if insufficient authorization
    //              No chunks uploaded if auth is insufficient!

    println!("✅ Success! Manifest CID: {}", hex::encode(result.manifest_cid.unwrap()));
    Ok(())
}</code></pre>
<h3 id="what-gets-checked-1"><a class="header" href="#what-gets-checked-1">What Gets Checked</a></h3>
<p>Before uploading <strong>any</strong> chunks, the SDK:</p>
<ol>
<li><strong>Calculates</strong> total requirements:
<ul>
<li>Number of transactions = number of chunks + 1 (for manifest)</li>
<li>Total bytes = file size + estimated manifest size</li>
</ul>
</li>
<li><strong>Queries</strong> blockchain for current authorization</li>
<li><strong>Validates</strong> sufficient transactions and bytes are authorized</li>
<li><strong>Fails immediately</strong> if insufficient (saves uploading time!)</li>
<li><strong>Proceeds</strong> only if authorization is sufficient</li>
</ol>
<h3 id="estimate-before-upload"><a class="header" href="#estimate-before-upload">Estimate Before Upload</a></h3>
<p>Check authorization requirements before starting:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Estimate what's needed
let file_size = std::fs::metadata("large-file.bin")?.len();
let (txs_needed, bytes_needed) = client.estimate_authorization(file_size, true);

println!("This upload will need:");
println!("  {} transactions", txs_needed);
println!("  {} bytes authorized", bytes_needed);

// For 100 MB file with 1 MiB chunks:
// - 100 chunk transactions
// - 1 manifest transaction
// - Total: 101 transactions, ~100 MB authorized
<span class="boring">}</span></code></pre>
<h3 id="handle-insufficient-authorization"><a class="header" href="#handle-insufficient-authorization">Handle Insufficient Authorization</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match client.store_chunked(&amp;data, config, options, None).await {
    Ok(result) =&gt; {
        println!("✅ Uploaded {} chunks", result.num_chunks);
        println!("   Manifest: {}", hex::encode(result.manifest_cid.unwrap()));
    }
    Err(Error::InsufficientAuthorization { need, available }) =&gt; {
        eprintln!("❌ Insufficient authorization:");
        eprintln!("   Need: {} bytes and {} transactions", need, /* calculate txs */);
        eprintln!("   Have: {} bytes available", available);
        eprintln!("\n💡 Authorize your account first:");
        eprintln!("   client.authorize_account(account, {}, {}).await?",
                  txs_needed, bytes_needed);
    }
    Err(e) =&gt; {
        eprintln!("❌ Error: {:?}", e);
    }
}
<span class="boring">}</span></code></pre>
<h3 id="complete-example-with-authorization-1"><a class="header" href="#complete-example-with-authorization-1">Complete Example with Authorization</a></h3>
<pre class="playground"><code class="language-rust">use bulletin_sdk_rust::prelude::*;
use std::path::Path;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Setup
    let ws_url = std::env::var("BULLETIN_WS_URL")
        .unwrap_or_else(|_| "ws://localhost:10000".to_string());
    let signer = /* your signer */;
    let account = /* your AccountId32 */;

    let submitter = SubxtSubmitter::from_url(&amp;ws_url, signer).await?;
    let client = AsyncBulletinClient::new(submitter)
        .with_account(account.clone());

    // Load file
    let file_path = Path::new("large-video.mp4");
    let data = std::fs::read(file_path)?;
    println!("📁 File: {} ({} bytes)", file_path.display(), data.len());

    // Estimate authorization needed
    let (txs_needed, bytes_needed) = client.estimate_authorization(data.len() as u64);
    println!("\n📊 Authorization Required:");
    println!("   Transactions: {}", txs_needed);
    println!("   Bytes: {}", bytes_needed);

    // Check if we need to authorize
    // (In real code, query current auth state first)
    println!("\n🔐 Authorizing account...");
    client.authorize_account(account, txs_needed, bytes_needed).await?;
    println!("✅ Authorization complete");

    // Configure chunking
    let config = ChunkerConfig {
        chunk_size: 1024 * 1024,  // 1 MiB
        max_parallel: 8,
        create_manifest: true,
    };

    // Upload with authorization checking (enabled by default)
    println!("\n⬆️  Uploading...");
    let start = std::time::Instant::now();

    let result = client
        .store_chunked(
            &amp;data,
            Some(config),
            StoreOptions::default(),
            Some(|event| {
                if let ProgressEvent::ChunkCompleted { index, total, .. } = event {
                    let percent = ((index + 1) as f64 / total as f64) * 100.0;
                    print!("\r   Progress: {:.1}%", percent);
                    std::io::Write::flush(&amp;mut std::io::stdout()).ok();
                }
            }),
        )
        .await?;

    let duration = start.elapsed();
    println!("\n\n✅ Upload complete in {:.2}s", duration.as_secs_f64());
    println!("   Manifest CID: {}", hex::encode(result.manifest_cid.unwrap()));
    println!("   {} chunks uploaded", result.num_chunks);

    Ok(())
}</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li><strong>Enable automatic authorization checking</strong> - Use <code>.with_account()</code> and the SDK automatically checks authorization before each upload, failing fast if insufficient</li>
<li><strong>Estimate requirements</strong> - Call <code>client.estimate_authorization(file_size)</code> before authorizing to know how much you need</li>
<li><strong>Choose appropriate chunk size</strong> - 1 MiB is a good default (balances transaction overhead vs. throughput)</li>
<li><strong>Enable progress tracking</strong> - Use <code>.with_callback()</code> to show users what’s happening</li>
<li><strong>Handle failures gracefully</strong> - The SDK will return <code>InsufficientAuthorization</code> error before wasting fees</li>
<li><strong>Keep manifest CID</strong> - Use it to retrieve the complete file from IPFS</li>
<li><strong>Test with MockSubmitter</strong> - Fast tests without a node</li>
</ol>
<blockquote>
<p><strong>Note</strong>: Authorization checking happens automatically inside <code>store().send()</code> when you configure <code>.with_account()</code>. You don’t need to manually check - the SDK does it for you!</p>
</blockquote>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<ul>
<li><a href="#authorization-2">Authorization</a> - Manage storage authorization</li>
<li><a href="rust/submitters.html">Transaction Submitters</a> - Custom submitter implementations</li>
<li><a href="#basic-storage">Basic Storage</a> - For small files &lt; 8 MiB</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="renewal"><a class="header" href="#renewal">Renewal</a></h1>
<p>This guide shows how to renew stored data using the Rust SDK to extend the retention period.</p>
<blockquote>
<p><strong>Prerequisites</strong>: Read <a href="#data-renewal">Data Renewal Concepts</a> first to understand the renewal flow.</p>
</blockquote>
<h2 id="the-complete-flow"><a class="header" href="#the-complete-flow">The Complete Flow</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

// 1. STORE - Submit data and get the transaction result
let operation = client.prepare_store(data, StoreOptions::default())?;
// Submit via subxt...
// let result = api.tx().transaction_storage().store(...).sign_and_submit_then_watch(...).await?;

// 2. RECEIVE EVENT - Extract block number and index from Stored event
let block_number = result.block_number;
let index = /* extract from Stored event in result.events */;

// 3. TRACK - Save for later renewal
let storage_ref = StorageRef::new(block_number, index);
// Save storage_ref to your database/storage...

// 4. RENEW (later) - When approaching expiration
let renewal = client.prepare_renew(storage_ref)?;
// Submit: api.tx().transaction_storage().renew(renewal.block, renewal.index)
<span class="boring">}</span></code></pre>
<h2 id="preparing-a-renewal"><a class="header" href="#preparing-a-renewal">Preparing a Renewal</a></h2>
<p>The SDK provides <code>prepare_renew()</code> to create renewal operations:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

let client = BulletinClient::new();

// From StorageRef
let storage_ref = StorageRef::new(1000, 5);  // block 1000, index 5
let renewal = client.prepare_renew(storage_ref)?;

// Or directly from raw values
let renewal = client.prepare_renew_raw(1000, 5)?;

// Submit via subxt
let tx = bulletin::tx()
    .transaction_storage()
    .renew(renewal.block, renewal.index);

let result = api
    .tx()
    .sign_and_submit_then_watch_default(&amp;tx, &amp;signer)
    .await?;
<span class="boring">}</span></code></pre>
<h2 id="extracting-events-after-storage"><a class="header" href="#extracting-events-after-storage">Extracting Events After Storage</a></h2>
<p>After storing data, extract the block number and index from the result:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use subxt::blocks::ExtrinsicEvents;

async fn store_and_track(
    api: &amp;OnlineClient&lt;BulletinConfig&gt;,
    signer: &amp;PairSigner,
    data: Vec&lt;u8&gt;,
) -&gt; Result&lt;StorageRef, Box&lt;dyn std::error::Error&gt;&gt; {
    let client = BulletinClient::new();
    let operation = client.prepare_store(data, StoreOptions::default())?;

    // Submit transaction
    let tx = bulletin::tx()
        .transaction_storage()
        .store(operation.data().to_vec(), None);

    let result = api
        .tx()
        .sign_and_submit_then_watch_default(&amp;tx, signer)
        .await?
        .wait_for_finalized_success()
        .await?;

    // Get block number
    let block_number = result.block_number();

    // Find Stored event and extract index
    let stored_event = result
        .find_first::&lt;bulletin::transaction_storage::events::Stored&gt;()?
        .ok_or("Stored event not found")?;

    let index = stored_event.index;

    Ok(StorageRef::new(block_number, index))
}
<span class="boring">}</span></code></pre>
<h2 id="using-renewaltracker"><a class="header" href="#using-renewaltracker">Using RenewalTracker</a></h2>
<p>For applications managing multiple stored items, use <code>RenewalTracker</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

// Create tracker
let mut tracker = RenewalTracker::new();

// Get retention period from chain (once)
let retention_period: u32 = api
    .constants()
    .at(&amp;bulletin::constants().transaction_storage().retention_period())?;

// After each store, track the entry
tracker.track(
    StorageRef::new(block_number, index),
    content_hash.to_vec(),
    data_size,
    retention_period,
);

// Periodically check for expiring entries
let current_block = api.blocks().at_latest().await?.number();
let buffer = 1000; // Renew 1000 blocks before expiration

let expiring = tracker.expiring_before(current_block + buffer);

for entry in expiring {
    // Prepare and submit renewal
    let renewal = client.prepare_renew(entry.storage_ref)?;

    let tx = bulletin::tx()
        .transaction_storage()
        .renew(renewal.block, renewal.index);

    let result = api
        .tx()
        .sign_and_submit_then_watch_default(&amp;tx, &amp;signer)
        .await?
        .wait_for_finalized_success()
        .await?;

    // Extract new block/index from Renewed event
    let renewed_event = result
        .find_first::&lt;bulletin::transaction_storage::events::Renewed&gt;()?
        .ok_or("Renewed event not found")?;

    let new_block = result.block_number();
    let new_index = renewed_event.index;

    // Update tracker with new reference
    tracker.update_after_renewal(
        entry.storage_ref,
        StorageRef::new(new_block, new_index),
        retention_period,
    );

    tracing::info!(
        old_block = entry.storage_ref.block,
        new_block = new_block,
        new_index = new_index,
        "Renewed storage"
    );
}
<span class="boring">}</span></code></pre>
<h2 id="persisting-tracker-state"><a class="header" href="#persisting-tracker-state">Persisting Tracker State</a></h2>
<p>For production use, persist the tracker state:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize)]
struct PersistedEntry {
    block: u32,
    index: u32,
    content_hash: Vec&lt;u8&gt;,
    size: u64,
    expires_at: u32,
}

// Save to database/file
fn save_entries(tracker: &amp;RenewalTracker) -&gt; Vec&lt;PersistedEntry&gt; {
    tracker.entries()
        .iter()
        .map(|e| PersistedEntry {
            block: e.storage_ref.block,
            index: e.storage_ref.index,
            content_hash: e.content_hash.clone(),
            size: e.size,
            expires_at: e.expires_at,
        })
        .collect()
}

// Restore from database/file
fn restore_entries(entries: Vec&lt;PersistedEntry&gt;) -&gt; RenewalTracker {
    let mut tracker = RenewalTracker::new();
    for e in entries {
        // Note: We store expires_at directly, so retention_period=0 works
        // because expires_at = block + retention_period was already computed
        tracker.track(
            StorageRef::new(e.block, e.index),
            e.content_hash,
            e.size,
            e.expires_at.saturating_sub(e.block), // Recover retention period
        );
    }
    tracker
}
<span class="boring">}</span></code></pre>
<h2 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

match client.prepare_renew(storage_ref) {
    Ok(renewal) =&gt; {
        // Submit renewal...
    }
    Err(Error::RenewalFailed(msg)) =&gt; {
        tracing::error!(reason = %msg, "Invalid renewal parameters");
    }
    Err(e) =&gt; {
        tracing::error!(?e, "Unexpected error");
    }
}

// Chain-level errors (from subxt)
match submit_renewal(&amp;api, &amp;signer, renewal).await {
    Ok(result) =&gt; { /* success */ }
    Err(e) if e.to_string().contains("RenewedNotFound") =&gt; {
        // Original transaction not found - data may have been pruned
        tracing::error!("Cannot renew: original data not found on chain");
    }
    Err(e) if e.to_string().contains("InsufficientAuthorization") =&gt; {
        // Need more authorization
        tracing::error!("Insufficient authorization for renewal");
    }
    Err(e) =&gt; {
        tracing::error!(?e, "Renewal failed");
    }
}
<span class="boring">}</span></code></pre>
<h2 id="complete-example-2"><a class="header" href="#complete-example-2">Complete Example</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;
use std::collections::HashMap;
use tracing::{info, error};

struct StorageManager {
    client: BulletinClient,
    tracker: RenewalTracker,
    retention_period: u32,
}

impl StorageManager {
    pub fn new(retention_period: u32) -&gt; Self {
        Self {
            client: BulletinClient::new(),
            tracker: RenewalTracker::new(),
            retention_period,
        }
    }

    /// Store data and track for renewal
    pub async fn store(
        &amp;mut self,
        api: &amp;OnlineClient&lt;BulletinConfig&gt;,
        signer: &amp;PairSigner,
        data: Vec&lt;u8&gt;,
    ) -&gt; Result&lt;(Vec&lt;u8&gt;, StorageRef)&gt; {
        let operation = self.client.prepare_store(data.clone(), StoreOptions::default())?;
        let cid = operation.calculate_cid()?.to_bytes()
            .ok_or(Error::StorageFailed("CID conversion failed".into()))?;

        // Submit
        let tx = bulletin::tx()
            .transaction_storage()
            .store(operation.data().to_vec(), None);

        let result = api.tx()
            .sign_and_submit_then_watch_default(&amp;tx, signer)
            .await?
            .wait_for_finalized_success()
            .await?;

        // Extract event
        let stored = result
            .find_first::&lt;bulletin::transaction_storage::events::Stored&gt;()?
            .ok_or(Error::StorageFailed("No Stored event".into()))?;

        let storage_ref = StorageRef::new(result.block_number(), stored.index);

        // Track
        self.tracker.track(
            storage_ref,
            stored.content_hash.to_vec(),
            data.len() as u64,
            self.retention_period,
        );

        info!(
            block = storage_ref.block,
            index = storage_ref.index,
            cid = %hex::encode(&amp;cid),
            "Stored and tracking for renewal"
        );

        Ok((cid, storage_ref))
    }

    /// Renew all entries expiring within `buffer` blocks
    pub async fn renew_expiring(
        &amp;mut self,
        api: &amp;OnlineClient&lt;BulletinConfig&gt;,
        signer: &amp;PairSigner,
        current_block: u32,
        buffer: u32,
    ) -&gt; Result&lt;u32&gt; {
        let expiring: Vec&lt;_&gt; = self.tracker
            .expiring_before(current_block + buffer)
            .iter()
            .map(|e| e.storage_ref)
            .collect();

        let mut renewed = 0;

        for storage_ref in expiring {
            match self.renew_one(api, signer, storage_ref).await {
                Ok(new_ref) =&gt; {
                    self.tracker.update_after_renewal(
                        storage_ref,
                        new_ref,
                        self.retention_period,
                    );
                    renewed += 1;
                }
                Err(e) =&gt; {
                    error!(?e, block = storage_ref.block, "Renewal failed");
                }
            }
        }

        Ok(renewed)
    }

    async fn renew_one(
        &amp;self,
        api: &amp;OnlineClient&lt;BulletinConfig&gt;,
        signer: &amp;PairSigner,
        storage_ref: StorageRef,
    ) -&gt; Result&lt;StorageRef&gt; {
        let renewal = self.client.prepare_renew(storage_ref)?;

        let tx = bulletin::tx()
            .transaction_storage()
            .renew(renewal.block, renewal.index);

        let result = api.tx()
            .sign_and_submit_then_watch_default(&amp;tx, signer)
            .await?
            .wait_for_finalized_success()
            .await?;

        let renewed = result
            .find_first::&lt;bulletin::transaction_storage::events::Renewed&gt;()?
            .ok_or(Error::RenewalFailed("No Renewed event".into()))?;

        Ok(StorageRef::new(result.block_number(), renewed.index))
    }
}
<span class="boring">}</span></code></pre>
<h2 id="next-steps-5"><a class="header" href="#next-steps-5">Next Steps</a></h2>
<ul>
<li><a href="#basic-storage">Basic Storage</a> - Storing data</li>
<li><a href="#chunked-uploads">Chunked Uploads</a> - Large file handling</li>
<li><a href="#data-retrieval">Data Retrieval</a> - Fetching via IPFS</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="mock-testing"><a class="header" href="#mock-testing">Mock Testing</a></h1>
<p>The Rust SDK provides <code>MockBulletinClient</code> for testing your application logic without requiring a running blockchain node.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p><code>MockBulletinClient</code> simulates blockchain operations without actually submitting transactions. It:</p>
<ul>
<li>Calculates real CIDs using the same logic as the real client</li>
<li>Tracks all operations performed for verification</li>
<li>Supports error simulation for testing failure paths</li>
<li>Provides the same builder pattern API as <code>AsyncBulletinClient</code></li>
</ul>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

#[tokio::test]
async fn test_store_data() {
    // Create mock client
    let client = MockBulletinClient::new();

    // Store data (no blockchain required)
    let data = b"Hello, Mock Bulletin!".to_vec();
    let result = client.store(data.clone()).send().await.unwrap();

    // Verify the CID was calculated
    assert_eq!(result.size, data.len() as u64);

    // Check operations performed
    let ops = client.operations();
    assert_eq!(ops.len(), 1);
    match &amp;ops[0] {
        MockOperation::Store { data_size, .. } =&gt; {
            assert_eq!(*data_size, data.len());
        },
        _ =&gt; panic!("Expected Store operation"),
    }
}
<span class="boring">}</span></code></pre>
<h2 id="builder-pattern"><a class="header" href="#builder-pattern">Builder Pattern</a></h2>
<p>The mock client supports the same builder pattern as the real client:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

#[tokio::test]
async fn test_builder_pattern() {
    let client = MockBulletinClient::new();
    let data = b"Test data".to_vec();

    let result = client
        .store(data)
        .with_codec(CidCodec::Raw)
        .with_hash_algorithm(HashAlgorithm::Blake2b256)
        .with_finalization(true)
        .send()
        .await
        .unwrap();

    assert!(result.cid.len() &gt; 0);
}
<span class="boring">}</span></code></pre>
<h2 id="error-simulation"><a class="header" href="#error-simulation">Error Simulation</a></h2>
<p>Test error handling by simulating failures:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

#[tokio::test]
async fn test_authorization_failure() {
    let mut config = MockClientConfig::default();
    config.simulate_auth_failure = true;

    let client = MockBulletinClient::with_config(config);
    let data = b"Test data".to_vec();

    let result = client.store(data).send().await;

    assert!(result.is_err());
    match result.unwrap_err() {
        Error::InsufficientAuthorization { .. } =&gt; {
            // Expected error
        },
        _ =&gt; panic!("Expected InsufficientAuthorization error"),
    }
}

#[tokio::test]
async fn test_storage_failure() {
    let mut config = MockClientConfig::default();
    config.simulate_storage_failure = true;

    let client = MockBulletinClient::with_config(config);
    let data = b"Test data".to_vec();

    let result = client.store(data).send().await;

    assert!(result.is_err());
    match result.unwrap_err() {
        Error::SubmissionFailed(msg) =&gt; {
            assert_eq!(msg, "Simulated storage failure");
        },
        _ =&gt; panic!("Expected SubmissionFailed error"),
    }
}
<span class="boring">}</span></code></pre>
<h2 id="verifying-operations"><a class="header" href="#verifying-operations">Verifying Operations</a></h2>
<p>Track all operations performed during testing:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

#[tokio::test]
async fn test_multiple_operations() {
    let client = MockBulletinClient::new();

    // Perform multiple stores
    client.store(b"Data 1".to_vec()).send().await.unwrap();
    client.store(b"Data 2".to_vec()).send().await.unwrap();
    client.store(b"Data 3".to_vec()).send().await.unwrap();

    // Verify all operations
    let ops = client.operations();
    assert_eq!(ops.len(), 3);

    // Clear for next test
    client.clear_operations();
    assert_eq!(client.operations().len(), 0);
}
<span class="boring">}</span></code></pre>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p>Customize the mock client behavior:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

let config = MockClientConfig {
    default_chunk_size: 512 * 1024, // 512 KiB
    max_parallel: 4,
    create_manifest: true,
    check_authorization_before_upload: true,
    chunking_threshold: 1 * 1024 * 1024, // 1 MiB
    simulate_auth_failure: false,
    simulate_storage_failure: false,
};

let client = MockBulletinClient::with_config(config);
<span class="boring">}</span></code></pre>
<h2 id="testing-authorization"><a class="header" href="#testing-authorization">Testing Authorization</a></h2>
<p>The mock client supports authorization operations:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;
use sp_runtime::AccountId32;

#[tokio::test]
async fn test_authorization() {
    let client = MockBulletinClient::new();

    // Test authorization estimation
    let estimate = client.estimate_authorization(10_000_000); // 10 MB
    assert!(estimate.0 &gt; 0); // transactions
    assert!(estimate.1 &gt; 0); // bytes
}
<span class="boring">}</span></code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<ol>
<li><strong>Use for Unit Tests</strong>: Mock client is perfect for testing application logic without blockchain overhead</li>
<li><strong>Verify CIDs</strong>: The mock calculates real CIDs, so you can verify correctness</li>
<li><strong>Test Error Paths</strong>: Use error simulation to ensure your error handling works</li>
<li><strong>Track Operations</strong>: Use <code>operations()</code> to verify the right operations were performed</li>
<li><strong>Clean State</strong>: Call <code>clear_operations()</code> between tests for isolation</li>
</ol>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<ul>
<li>Does not actually submit transactions to a blockchain</li>
<li>Does not validate on-chain state or permissions</li>
<li>Block numbers are always mock values (1)</li>
<li>No actual data retention or storage limits</li>
</ul>
<p>For integration tests that require real blockchain interaction, use <code>AsyncBulletinClient</code> with a local test node.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="no_std-support"><a class="header" href="#no_std-support">no_std Support</a></h1>
<p>The Rust SDK is designed to be compatible with <code>no_std</code> environments, making it ideal for use in constrained environments like embedded systems or WebAssembly runtimes.</p>
<blockquote>
<p><strong>Important</strong>: The <code>no_std</code> feature is for <strong>data preparation and verification</strong> only. You cannot call <code>store()</code> or <code>retrieve()</code> methods in no_std contexts. These high-level APIs require networking and async support which are only available with the <code>std</code> feature.</p>
</blockquote>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<p>Disable default features in your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
bulletin-sdk-rust = { version = "0.1", default-features = false }
</code></pre>
<h2 id="limitations-in-no_std"><a class="header" href="#limitations-in-no_std">Limitations in <code>no_std</code></a></h2>
<p>When using the SDK without the <code>std</code> feature:</p>
<ul>
<li><strong>No <code>store()</code> or <code>retrieve()</code></strong>: High-level client APIs require std for networking</li>
<li><strong>No Networking</strong>: Cannot use <code>subxt</code> or connect to nodes</li>
<li><strong>No Async</strong>: Async/await requires std library support</li>
<li><strong>Data Preparation Only</strong>: Use for CID calculation, chunking, and verification</li>
</ul>
<h2 id="what-works-in-no_std"><a class="header" href="#what-works-in-no_std">What Works in <code>no_std</code></a></h2>
<p>The following SDK features are fully functional in no_std environments:</p>
<ul>
<li>✅ <strong>CID Calculation</strong>: Compute CIDs for any data</li>
<li>✅ <strong>Chunking</strong>: Split data into optimal chunks</li>
<li>✅ <strong>DAG-PB Generation</strong>: Create IPFS-compatible manifests</li>
<li>✅ <strong>Authorization Helpers</strong>: Calculate required authorization</li>
<li>✅ <strong>Type Definitions</strong>: All core types are no_std compatible</li>
</ul>
<h2 id="example-verifying-a-cid"><a class="header" href="#example-verifying-a-cid">Example: Verifying a CID</a></h2>
<p>You can use the SDK to verify that data matches a claimed CID in constrained environments:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>#![no_std]
<span class="boring">fn main() {
</span>use bulletin_sdk_rust::prelude::*;

fn verify_upload(data: &amp;[u8], claimed_cid: &amp;[u8]) -&gt; bool {
    let calculated = calculate_cid_default(data).expect("Failed to calc CID");
    let cid_bytes = cid_to_bytes(&amp;calculated).expect("Failed to convert");

    // Compare bytes
    cid_bytes.to_bytes() == claimed_cid
}
<span class="boring">}</span></code></pre>
<h2 id="example-preparing-chunked-data"><a class="header" href="#example-preparing-chunked-data">Example: Preparing Chunked Data</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>#![no_std]
<span class="boring">fn main() {
</span>use bulletin_sdk_rust::{chunker::{Chunker, FixedSizeChunker}, types::ChunkerConfig};
extern crate alloc;
use alloc::vec::Vec;

fn prepare_chunks(data: &amp;[u8]) -&gt; Vec&lt;Vec&lt;u8&gt;&gt; {
    let config = ChunkerConfig {
        chunk_size: 1024 * 1024, // 1 MiB chunks
        max_parallel: 1, // Serial processing in no_std
        create_manifest: false,
    };

    let chunker = FixedSizeChunker::new(config);
    let chunks = chunker.chunk(data).expect("Failed to chunk");

    chunks.into_iter().map(|c| c.data).collect()
}
<span class="boring">}</span></code></pre>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<p><strong>Embedded Systems</strong>: Calculate CIDs on IoT devices before uploading via a gateway.</p>
<p><strong>WASM Modules</strong>: Use in WebAssembly modules for client-side data preparation and verification.</p>
<p><strong>Substrate Pallets</strong>: Use CID calculation and chunking logic for <strong>on-chain verification</strong> (e.g., verify that submitted data matches a claimed CID). Note: You cannot use the <code>store()</code> API in pallets - that’s for off-chain clients only.</p>
<p><strong>Resource-Constrained Environments</strong>: Run CID calculations on systems without std library support.</p>
<h2 id="memory-considerations"><a class="header" href="#memory-considerations">Memory Considerations</a></h2>
<p>In no_std environments, be mindful of memory constraints:</p>
<ul>
<li>Use streaming chunking for large files</li>
<li>Process one chunk at a time instead of loading all data into memory</li>
<li>Consider chunk size based on available RAM</li>
<li>Use iterators where possible to avoid allocations</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="typescript-sdk"><a class="header" href="#typescript-sdk">TypeScript SDK</a></h1>
<p>The <code>@bulletin/sdk</code> package provides a modern, type-safe client for Node.js and Browser environments.</p>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<h3 id="core-storage"><a class="header" href="#core-storage">Core Storage</a></h3>
<ul>
<li><strong>Unified API</strong>: Single <code>store()</code> method handles both small and large files</li>
<li><strong>Automatic Chunking</strong>: Files larger than 2 MiB are automatically chunked</li>
<li><strong>Progress Tracking</strong>: Real-time callbacks for upload progress</li>
<li><strong>DAG-PB Manifests</strong>: IPFS-compatible manifest generation</li>
<li><strong>CID Support</strong>: Multiple codecs (Raw, DAG-PB, DAG-CBOR) and hash algorithms</li>
</ul>
<h3 id="authorization-management"><a class="header" href="#authorization-management">Authorization Management</a></h3>
<ul>
<li><strong>Pre-flight Checking</strong>: Queries blockchain before upload to fail fast</li>
<li><strong>Expiration Validation</strong>: Automatically checks if authorization has expired</li>
<li><strong>Fail Fast</strong>: Saves transaction fees by validating before submission</li>
<li><strong>Complete Operations</strong>: Authorize, refresh, and manage authorizations</li>
</ul>
<h3 id="developer-experience"><a class="header" href="#developer-experience">Developer Experience</a></h3>
<ul>
<li><strong>Full Type Support</strong>: Written in TypeScript with complete definitions</li>
<li><strong>Direct PAPI Integration</strong>: Tightly coupled to Polkadot API for type-safe blockchain interaction</li>
<li><strong>Builder Pattern</strong>: Fluent API for configuring store operations</li>
<li><strong>Isomorphic</strong>: Works in Node.js, Browsers, and other JS runtimes</li>
<li><strong>Mock Support</strong>: <code>MockBulletinClient</code> for testing without a blockchain node</li>
</ul>
<h2 id="quick-example"><a class="header" href="#quick-example">Quick Example</a></h2>
<pre><code class="language-typescript">import { AsyncBulletinClient } from '@bulletin/sdk';
import { createClient } from 'polkadot-api';
import { getWsProvider } from 'polkadot-api/ws-provider/node';

// Setup PAPI client
const wsProvider = getWsProvider('wss://bulletin-rpc.polkadot.io');
const papiClient = createClient(wsProvider);
const api = papiClient.getTypedApi(bulletinDescriptor);

// Create SDK client with PAPI client and signer
const client = new AsyncBulletinClient(api, signer)
    .withAccount(account);  // Enable authorization checking

// Store any size file using builder pattern
const data = new Uint8Array(50_000_000); // 50 MB
const result = await client.store(data).send();

console.log('Stored with CID:', result.cid.toString());
</code></pre>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>Proceed to <a href="#installation-1">Installation</a> to get started.</p>
<h2 id="guides"><a class="header" href="#guides">Guides</a></h2>
<ul>
<li><a href="#basic-storage-1">Basic Storage</a> - Store small files with a single transaction</li>
<li><a href="#chunked-uploads-1">Chunked Uploads</a> - Handle large files with automatic chunking</li>
<li><a href="#papi-integration">PAPI Integration</a> - Integrate with Polkadot API</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="installation-1"><a class="header" href="#installation-1">Installation</a></h1>
<p>Install the package via your package manager:</p>
<pre><code class="language-bash">npm install @bulletin/sdk
# or
yarn add @bulletin/sdk
# or
pnpm add @bulletin/sdk
</code></pre>
<h2 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h2>
<p>We recommend using Polkadot API (PAPI) to let the sdk interact with the chain:</p>
<pre><code class="language-bash">npm install polkadot-api
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="basic-storage-1"><a class="header" href="#basic-storage-1">Basic Storage</a></h1>
<p>This guide shows how to store data using the <code>AsyncBulletinClient</code> with direct PAPI integration.</p>
<blockquote>
<p><strong>Implementation Status</strong>: CID calculation, chunking, and DAG-PB manifest generation are fully functional.
Transaction submission for <code>store().send()</code> is not yet implemented (throws <code>NOT_IMPLEMENTED</code>).
Authorization operations (<code>authorizeAccount</code>, <code>authorizePreimage</code>, <code>renew</code>) work.
See the <a href="../../../examples">examples</a> directory for current working patterns using PAPI directly.</p>
</blockquote>
<h2 id="quick-start-3"><a class="header" href="#quick-start-3">Quick Start</a></h2>
<p>The <code>store()</code> method with builder pattern automatically handles both small and large files:</p>
<pre><code class="language-typescript">import { AsyncBulletinClient } from '@bulletin/sdk';
import { createClient, Binary } from 'polkadot-api';
import { getWsProvider } from 'polkadot-api/ws-provider/node';

// 1. Connect to Bulletin Chain
const wsProvider = getWsProvider('ws://localhost:9944');
const papiClient = createClient(wsProvider);
const api = papiClient.getTypedApi(bulletinDescriptor);

// 2. Create client with PAPI client and signer
const client = new AsyncBulletinClient(api, signer);

// 3. Store data using builder pattern (automatically chunks if &gt; 2 MiB)
const data = Binary.fromText('Hello, Bulletin Chain!');
const result = await client.store(data).send();

console.log('✅ Stored successfully!');
console.log('   CID:', result.cid.toString());
console.log('   Size:', result.size, 'bytes');
</code></pre>
<h2 id="step-by-step-explanation-1"><a class="header" href="#step-by-step-explanation-1">Step-by-Step Explanation</a></h2>
<h3 id="1-setup-connection-1"><a class="header" href="#1-setup-connection-1">1. Setup Connection</a></h3>
<p>First, create a PAPI client and get the typed API:</p>
<pre><code class="language-typescript">import { createClient } from 'polkadot-api';
import { getWsProvider } from 'polkadot-api/ws-provider/node';

// Connect to chain
const wsProvider = getWsProvider('ws://localhost:9944');
const papiClient = createClient(wsProvider);

// Get typed API (requires chain descriptors)
const api = papiClient.getTypedApi(bulletinDescriptor);
</code></pre>
<h3 id="2-create-client-1"><a class="header" href="#2-create-client-1">2. Create Client</a></h3>
<p>Create the SDK client with PAPI client and signer:</p>
<pre><code class="language-typescript">import { AsyncBulletinClient } from '@bulletin/sdk';

const client = new AsyncBulletinClient(api, signer);
</code></pre>
<h3 id="3-prepare-data-1"><a class="header" href="#3-prepare-data-1">3. Prepare Data</a></h3>
<p>Use PAPI’s <code>Binary</code> class to handle data:</p>
<pre><code class="language-typescript">import { Binary } from 'polkadot-api';

// From text
const data = Binary.fromText('Hello, Bulletin!');

// From hex string
const data = Binary.fromHex('0x48656c6c6f');

// From Uint8Array
const data = Binary.fromBytes(new Uint8Array([72, 101, 108, 108, 111]));

// From Buffer (Node.js)
const data = Binary.fromBytes(Buffer.from('Hello'));
</code></pre>
<h3 id="4-store-data"><a class="header" href="#4-store-data">4. Store Data</a></h3>
<p>The <code>store()</code> method with builder pattern handles everything:</p>
<ul>
<li>Validates data size</li>
<li>Checks authorization (if configured)</li>
<li>Automatically chunks large files (&gt; 2 MiB by default)</li>
<li>Calculates CID(s)</li>
<li>Submits transaction(s)</li>
<li>Waits for finalization</li>
</ul>
<pre><code class="language-typescript">// Basic store
const result = await client.store(data).send();

// With custom options
const result = await client
    .store(data)
    .withCodec(CidCodec.Raw)
    .withHashAlgorithm(HashAlgorithm.Blake2b256)
    .withFinalization(true)
    .send();

// With progress tracking for large files
const result = await client
    .store(data)
    .withCallback((event) =&gt; {
        if (event.type === 'chunk_completed') {
            console.log(`Chunk ${event.index + 1}/${event.total} uploaded`);
        } else if (event.type === 'completed') {
            console.log('Upload complete!');
        }
    })
    .send();
</code></pre>
<h3 id="5-handle-result-1"><a class="header" href="#5-handle-result-1">5. Handle Result</a></h3>
<pre><code class="language-typescript">console.log('CID:', result.cid.toString());
console.log('Size:', result.size, 'bytes');
console.log('Block:', result.blockNumber);

// If chunked, check chunk details
if (result.chunks) {
    console.log('Chunks:', result.chunks.numChunks);
    console.log('Chunk CIDs:', result.chunks.chunkCids.map(c =&gt; c.toString()));
}
</code></pre>
<h2 id="authorization-checking-fail-fast-2"><a class="header" href="#authorization-checking-fail-fast-2">Authorization Checking (Fail Fast)</a></h2>
<p>By default, the SDK checks authorization <strong>before</strong> uploading to fail fast and avoid wasted transaction fees.</p>
<h3 id="how-it-works-3"><a class="header" href="#how-it-works-3">How It Works</a></h3>
<pre><code class="language-typescript">import { AsyncBulletinClient } from '@bulletin/sdk';
import { Binary } from 'polkadot-api';

// 1. Create client with your account
const account = 'your-account-address';

const client = new AsyncBulletinClient(api, signer)
    .withAccount(account);  // Set the account for auth checking

// 2. Upload - authorization is checked automatically
const data = Binary.fromText('Hello, Bulletin!');
const result = await client.store(data).send();
//                       ⬆️ Queries blockchain first, fails fast if insufficient auth
</code></pre>
<h3 id="what-gets-checked-2"><a class="header" href="#what-gets-checked-2">What Gets Checked</a></h3>
<p>Before submitting the transaction, the SDK:</p>
<ol>
<li><strong>Queries</strong> the blockchain for your current authorization</li>
<li><strong>Validates</strong> you have enough transactions and bytes authorized</li>
<li><strong>Checks expiration</strong> - fails if authorization has expired</li>
<li><strong>Fails immediately</strong> if insufficient (no transaction fees wasted!)</li>
<li><strong>Proceeds</strong> only if authorization is sufficient</li>
</ol>
<h3 id="disable-authorization-checking"><a class="header" href="#disable-authorization-checking">Disable Authorization Checking</a></h3>
<p>If you want to skip the check (e.g., you know authorization exists):</p>
<pre><code class="language-typescript">const client = new AsyncBulletinClient(api, signer, {
    checkAuthorizationBeforeUpload: false,  // Disable checking
}).withAccount(account);
</code></pre>
<h3 id="error-example-1"><a class="header" href="#error-example-1">Error Example</a></h3>
<pre><code class="language-typescript">import { BulletinError } from '@bulletin/sdk';

try {
    const result = await client.store(data).send();
    console.log('Success!');
} catch (error) {
    if (error instanceof BulletinError) {
        if (error.code === 'INSUFFICIENT_AUTHORIZATION') {
            console.error('Need more authorization!');
            console.error('Details:', error.cause);
        } else if (error.code === 'AUTHORIZATION_EXPIRED') {
            console.error('Authorization expired!');
            console.error('Details:', error.cause);
        }
    } else {
        console.error('Error:', error);
    }
}
</code></pre>
<h2 id="complete-example-with-authorization-2"><a class="header" href="#complete-example-with-authorization-2">Complete Example with Authorization</a></h2>
<pre><code class="language-typescript">import { AsyncBulletinClient } from '@bulletin/sdk';
import { createClient, Binary } from 'polkadot-api';
import { getWsProvider } from 'polkadot-api/ws-provider/node';

const wsProvider = getWsProvider('ws://localhost:9944');
const papiClient = createClient(wsProvider);
const api = papiClient.getTypedApi(bulletinDescriptor);

// Create client with account for authorization checking
const account = 'your-account-address';
const client = new AsyncBulletinClient(api, signer)
    .withAccount(account);

// Estimate what's needed
const data = Binary.fromBytes(new Uint8Array(5_000_000)); // 5 MB
const estimate = client.estimateAuthorization(data.asBytes().length);
console.log('Need authorization for', estimate.transactions, 'txs and', estimate.bytes, 'bytes');

// Authorize (if needed - requires sudo)
// await client.authorizeAccount(account, estimate.transactions, BigInt(estimate.bytes));

try {
    // Store - will check authorization automatically
    const result = await client.store(data).send();
    console.log('✅ Stored:', result.cid.toString());
} catch (error) {
    if (error instanceof BulletinError) {
        if (error.code === 'INSUFFICIENT_AUTHORIZATION') {
            console.error('❌ Insufficient authorization');
            console.error('   Please authorize your account first');
        } else if (error.code === 'AUTHORIZATION_EXPIRED') {
            console.error('❌ Authorization expired');
            console.error('   Please refresh your authorization');
        }
    } else {
        console.error('❌ Error:', error);
    }
}
</code></pre>
<h2 id="working-with-different-data-types"><a class="header" href="#working-with-different-data-types">Working with Different Data Types</a></h2>
<h3 id="text-data"><a class="header" href="#text-data">Text Data</a></h3>
<pre><code class="language-typescript">import { Binary } from 'polkadot-api';

const data = Binary.fromText('Hello, Bulletin Chain!');
const result = await client.store(data).send();
</code></pre>
<h3 id="binary-data"><a class="header" href="#binary-data">Binary Data</a></h3>
<pre><code class="language-typescript">// From Uint8Array
const bytes = new Uint8Array([1, 2, 3, 4, 5]);
const data = Binary.fromBytes(bytes);
const result = await client.store(data).send();
</code></pre>
<h3 id="file-data-nodejs"><a class="header" href="#file-data-nodejs">File Data (Node.js)</a></h3>
<pre><code class="language-typescript">import { readFile } from 'fs/promises';
import { Binary } from 'polkadot-api';

const fileBuffer = await readFile('document.pdf');
const data = Binary.fromBytes(fileBuffer);
const result = await client.store(data).send();
</code></pre>
<h3 id="json-data"><a class="header" href="#json-data">JSON Data</a></h3>
<pre><code class="language-typescript">import { Binary } from 'polkadot-api';

const jsonData = { message: 'Hello', timestamp: Date.now() };
const jsonString = JSON.stringify(jsonData);
const data = Binary.fromText(jsonString);
const result = await client.store(data).send();
</code></pre>
<h2 id="testing-without-a-node-1"><a class="header" href="#testing-without-a-node-1">Testing Without a Node</a></h2>
<p>For unit tests, use the <code>MockBulletinClient</code>:</p>
<pre><code class="language-typescript">import { MockBulletinClient } from '@bulletin/sdk';
import { Binary } from 'polkadot-api';

// Create mock client (no blockchain required)
const client = new MockBulletinClient();

// Store data - calculates real CIDs but doesn't submit to chain
const data = Binary.fromText('Test data');
const result = await client.store(data).send();

// Verify operations performed
const ops = client.getOperations();
expect(ops).toHaveLength(1);
expect(ops[0].type).toBe('store');
</code></pre>
<p>See the <a href="#mock-testing">Mock Testing</a> guide for more details.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chunked-uploads-1"><a class="header" href="#chunked-uploads-1">Chunked Uploads</a></h1>
<p>The Bulletin SDK automatically handles chunking for large files. When you call <code>store()</code>, files larger than the threshold (default 2 MiB) are automatically split into chunks.</p>
<blockquote>
<p><strong>Implementation Status</strong>: CID calculation, chunking, and DAG-PB manifest generation are fully functional.
Transaction submission for <code>store().send()</code> is not yet implemented (throws <code>NOT_IMPLEMENTED</code>).
Use <code>storeChunked()</code> for CID calculation and manifest generation, then submit transactions via PAPI directly.</p>
</blockquote>
<h2 id="automatic-chunking-recommended-1"><a class="header" href="#automatic-chunking-recommended-1">Automatic Chunking (Recommended)</a></h2>
<p>For most use cases, simply use <code>store()</code> - it automatically chunks large files:</p>
<pre><code class="language-typescript">import { AsyncBulletinClient } from '@bulletin/sdk';

const client = new AsyncBulletinClient(api, signer);

// Load file of any size
const data = new Uint8Array(50 * 1024 * 1024); // 50 MB

// Automatically chunks if &gt; 2 MiB
const result = await client
    .store(data)
    .withCallback((event) =&gt; {
        if (event.type === 'chunk_completed') {
            console.log(`Chunk ${event.index + 1}/${event.total} uploaded`);
        } else if (event.type === 'completed') {
            console.log('Done!');
        }
    })
    .send();

console.log('Stored with CID:', result.cid.toString());
if (result.chunks) {
    console.log('Chunked into', result.chunks.numChunks, 'pieces');
}
</code></pre>
<h3 id="configuring-automatic-chunking-1"><a class="header" href="#configuring-automatic-chunking-1">Configuring Automatic Chunking</a></h3>
<p>You can configure the threshold and chunk size via the client constructor:</p>
<pre><code class="language-typescript">const client = new AsyncBulletinClient(api, signer, {
    chunkingThreshold: 5 * 1024 * 1024,  // Chunk files &gt; 5 MiB
    defaultChunkSize: 2 * 1024 * 1024,   // 2 MiB chunks
    maxParallel: 8,                       // Upload 8 chunks in parallel
    createManifest: true,                 // Create DAG-PB manifest
    checkAuthorizationBeforeUpload: true, // Check auth before upload
});
</code></pre>
<h2 id="advanced-manual-chunking-1"><a class="header" href="#advanced-manual-chunking-1">Advanced: Manual Chunking</a></h2>
<p>For advanced use cases where you need explicit control over chunking parameters, use <code>storeChunked()</code>:</p>
<pre><code class="language-typescript">import { AsyncBulletinClient } from '@bulletin/sdk';

const client = new AsyncBulletinClient(api, signer);

const largeFile = new Uint8Array(100 * 1024 * 1024); // 100 MB

// Configure chunking explicitly
const config = {
    chunkSize: 1024 * 1024,  // 1 MiB chunks
    maxParallel: 8,           // Upload 8 chunks in parallel
    createManifest: true,     // Create DAG-PB manifest
};

// Progress tracking
const progressCallback = (event) =&gt; {
    switch (event.type) {
        case 'chunk_started':
            console.log(`Uploading chunk ${event.index + 1}/${event.total}`);
            break;
        case 'chunk_completed':
            console.log(`✓ Chunk ${event.index + 1}/${event.total} complete:`, event.cid.toString());
            break;
        case 'chunk_failed':
            console.error(`✗ Chunk ${event.index + 1}/${event.total} failed:`, event.error);
            break;
        case 'manifest_created':
            console.log('📦 Manifest created:', event.cid.toString());
            break;
        case 'completed':
            if (event.manifestCid) {
                console.log('✅ All done! Manifest CID:', event.manifestCid.toString());
            }
            break;
    }
};

// Upload with manual chunking configuration and progress tracking
const result = await client.storeChunked(
    largeFile,
    config,
    undefined, // default store options
    progressCallback
);

console.log('\n📊 Upload Summary:');
console.log('   Total size:', result.totalSize, 'bytes');
console.log('   Chunks:', result.numChunks);
console.log('   Chunk CIDs:', result.chunkCids.length, 'items');
if (result.manifestCid) {
    console.log('   Manifest CID:', result.manifestCid.toString());
}
</code></pre>
<h2 id="how-it-works-4"><a class="header" href="#how-it-works-4">How It Works</a></h2>
<p>The <code>storeChunked()</code> method:</p>
<ol>
<li><strong>Splits data</strong> into chunks (default 1 MiB)</li>
<li><strong>Calculates CIDs</strong> for each chunk</li>
<li><strong>Submits chunks</strong> sequentially or in parallel</li>
<li><strong>Creates DAG-PB manifest</strong> linking all chunks</li>
<li><strong>Submits manifest</strong> as final transaction</li>
<li><strong>Returns result</strong> with all CIDs</li>
</ol>
<h3 id="when-to-use-storechunked-vs-store"><a class="header" href="#when-to-use-storechunked-vs-store">When to Use <code>storeChunked()</code> vs <code>store()</code></a></h3>
<p><strong>Use <code>store()</code> (recommended):</strong></p>
<ul>
<li>For most use cases - it automatically handles everything</li>
<li>When you don’t need detailed chunk information</li>
<li>For both small and large files</li>
</ul>
<p><strong>Use <code>storeChunked()</code> (advanced):</strong></p>
<ul>
<li>When you need detailed control over chunking parameters</li>
<li>When you need the full <code>ChunkedStoreResult</code> with all chunk CIDs</li>
<li>When you want to force chunking on small files</li>
<li>For testing or debugging chunking behavior</li>
</ul>
<p><strong>Key Difference:</strong></p>
<ul>
<li><code>store()</code> returns <code>StoreResult</code> with optional chunk info</li>
<li><code>storeChunked()</code> returns <code>ChunkedStoreResult</code> with detailed chunk information</li>
</ul>
<h2 id="configuration-options-1"><a class="header" href="#configuration-options-1">Configuration Options</a></h2>
<h3 id="chunk-size-1"><a class="header" href="#chunk-size-1">Chunk Size</a></h3>
<pre><code class="language-typescript">const config = {
    chunkSize: 2 * 1024 * 1024,  // 2 MiB chunks (max is 2 MiB for Bitswap)
    maxParallel: 4,
    createManifest: true,
};
</code></pre>
<p><strong>Guidelines:</strong></p>
<ul>
<li>Minimum: 1 MiB (1,048,576 bytes)</li>
<li>Maximum: 2 MiB (2,097,152 bytes) - Bitswap compatibility limit</li>
<li>Default: 1 MiB - good balance of efficiency and compatibility</li>
</ul>
<h3 id="parallel-uploads-1"><a class="header" href="#parallel-uploads-1">Parallel Uploads</a></h3>
<pre><code class="language-typescript">const config = {
    chunkSize: 1024 * 1024,
    maxParallel: 8,  // Upload up to 8 chunks simultaneously
    createManifest: true,
};
</code></pre>
<p><strong>Note</strong>: Current implementation uploads sequentially. Parallel support is planned for a future release.</p>
<h3 id="manifest-creation-1"><a class="header" href="#manifest-creation-1">Manifest Creation</a></h3>
<pre><code class="language-typescript">// With manifest (IPFS-compatible, recommended)
const config = {
    chunkSize: 1024 * 1024,
    maxParallel: 8,
    createManifest: true,  // Creates DAG-PB manifest
};

// Without manifest (just upload chunks)
const config = {
    chunkSize: 1024 * 1024,
    maxParallel: 8,
    createManifest: false,  // No manifest, just chunks
};
</code></pre>
<h2 id="progress-tracking-1"><a class="header" href="#progress-tracking-1">Progress Tracking</a></h2>
<p>Track upload progress with callbacks:</p>
<pre><code class="language-typescript">const progress = (event) =&gt; {
    switch (event.type) {
        case 'chunk_started':
            console.log(`[${event.index + 1}/${event.total}] Starting chunk...`);
            break;
        case 'chunk_completed':
            console.log(`[${event.index + 1}/${event.total}] ✓ Uploaded:`, event.cid.toString());
            break;
        case 'chunk_failed':
            console.error(`[${event.index + 1}/${event.total}] ✗ Failed:`, event.error.message);
            break;
        case 'manifest_started':
            console.log('Creating manifest...');
            break;
        case 'manifest_created':
            console.log('Manifest CID:', event.cid.toString());
            break;
        case 'completed':
            if (event.manifestCid) {
                console.log('All done! Manifest:', event.manifestCid.toString());
            }
            break;
    }
};

const result = await client
    .store(largeData)
    .withCallback(progress)
    .send();
</code></pre>
<h2 id="authorization-checking-fail-fast-3"><a class="header" href="#authorization-checking-fail-fast-3">Authorization Checking (Fail Fast)</a></h2>
<p>By default, the SDK checks authorization <strong>before</strong> uploading chunked data to avoid wasted time and fees.</p>
<h3 id="how-it-works-1-1"><a class="header" href="#how-it-works-1-1">How It Works</a></h3>
<pre><code class="language-typescript">// 1. Create client with account
const client = new AsyncBulletinClient(api, signer)
    .withAccount(account);  // Enable automatic authorization checking

// 2. Upload large file - authorization checked automatically
const largeData = new Uint8Array(50 * 1024 * 1024);
const result = await client.store(largeData).send();
//   Internally:
//   - Queries authorization (if account set)
//   - Checks expiration (if expires_at present)
//   - Validates sufficient bytes and transactions
//   - Fails with AuthorizationExpired or InsufficientAuthorization
//   - Only proceeds if all checks pass
</code></pre>
<h3 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h3>
<pre><code class="language-typescript">import { BulletinError } from '@bulletin/sdk';

try {
    const result = await client.store(largeData).send();
    console.log('Success!');
} catch (error) {
    if (error instanceof BulletinError) {
        if (error.code === 'INSUFFICIENT_AUTHORIZATION') {
            console.error('Need more authorization for', largeData.length, 'bytes');

            // Estimate what's needed
            const estimate = client.estimateAuthorization(largeData.length);
            console.error('Need:', estimate.transactions, 'txs,', estimate.bytes, 'bytes');
        } else if (error.code === 'AUTHORIZATION_EXPIRED') {
            console.error('Authorization expired - please refresh');
        }
    }
}
</code></pre>
<h2 id="complete-example-with-authorization-3"><a class="header" href="#complete-example-with-authorization-3">Complete Example with Authorization</a></h2>
<pre><code class="language-typescript">import { AsyncBulletinClient, BulletinError } from '@bulletin/sdk';

const account = 'your-account-address';
const client = new AsyncBulletinClient(api, signer)
    .withAccount(account);

// Large file
const largeFile = new Uint8Array(100 * 1024 * 1024); // 100 MB

// Estimate authorization needed
const estimate = client.estimateAuthorization(largeFile.length);
console.log('Authorization needed:');
console.log('   Transactions:', estimate.transactions);
console.log('   Bytes:', estimate.bytes);

// Authorize (if needed - requires sudo)
// await client.authorizeAccount(account, estimate.transactions, BigInt(estimate.bytes));

try {
    // Upload with progress tracking
    const result = await client
        .store(largeFile)
        .withCallback((event) =&gt; {
            if (event.type === 'chunk_completed') {
                console.log(`Chunk ${event.index + 1}/${event.total} done`);
            }
        })
        .send();

    console.log('Upload complete!');
    console.log('   CID:', result.cid.toString());
    if (result.chunks) {
        console.log('   Chunks:', result.chunks.numChunks);
    }
} catch (error) {
    if (error instanceof BulletinError) {
        if (error.code === 'INSUFFICIENT_AUTHORIZATION') {
            console.error('Insufficient authorization');
        } else if (error.code === 'AUTHORIZATION_EXPIRED') {
            console.error('Authorization expired');
        }
    } else {
        console.error('Error:', error);
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="papi-integration"><a class="header" href="#papi-integration">PAPI Integration</a></h1>
<p>The TypeScript SDK is tightly coupled to Polkadot API (PAPI) for blockchain interaction. You must provide a configured PAPI client and signer when creating the SDK client.</p>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<p>First, install the required dependencies:</p>
<pre><code class="language-bash">npm install polkadot-api @polkadot-labs/hdkd @polkadot-labs/hdkd-helpers
</code></pre>
<h2 id="basic-connection"><a class="header" href="#basic-connection">Basic Connection</a></h2>
<pre><code class="language-typescript">import { createClient } from 'polkadot-api';
import { getWsProvider } from 'polkadot-api/ws-provider/node';
import { AsyncBulletinClient } from '@bulletin/sdk';
import { sr25519CreateDerive } from '@polkadot-labs/hdkd';
import { getPolkadotSigner } from 'polkadot-api/signer';
import { DEV_PHRASE } from '@polkadot-labs/hdkd-helpers';

// 1. Setup WebSocket connection
const wsProvider = getWsProvider('ws://localhost:9944');
const papiClient = createClient(wsProvider);

// 2. Get typed API (you'll need chain descriptors)
const api = papiClient.getTypedApi(bulletinDescriptor);

// 3. Create signer
const keyring = sr25519CreateDerive(DEV_PHRASE);
const signer = getPolkadotSigner(
    keyring.derive("//Alice"),
    "Alice",
    42 // Bulletin chain ID
);

// 4. Create SDK client with PAPI client and signer
const client = new AsyncBulletinClient(api, signer);

// 5. Use the client
const data = new TextEncoder().encode('Hello, Bulletin!');
const result = await client.store(data).send();

console.log('Stored with CID:', result.cid.toString());
</code></pre>
<h2 id="chain-descriptors"><a class="header" href="#chain-descriptors">Chain Descriptors</a></h2>
<p>You’ll need to generate chain descriptors for your Bulletin Chain instance. These provide type information to PAPI:</p>
<pre><code class="language-bash">npx papi add wss://bulletin-rpc.polkadot.io -n bulletin
</code></pre>
<p>This creates a <code>bulletin</code> descriptor you can import:</p>
<pre><code class="language-typescript">import { bulletin } from 'polkadot-api/descriptors';

const api = papiClient.getTypedApi(bulletin);
</code></pre>
<h2 id="using-different-signers"><a class="header" href="#using-different-signers">Using Different Signers</a></h2>
<h3 id="development-accounts"><a class="header" href="#development-accounts">Development Accounts</a></h3>
<p>For testing, use dev accounts:</p>
<pre><code class="language-typescript">import { sr25519CreateDerive } from '@polkadot-labs/hdkd';
import { getPolkadotSigner } from 'polkadot-api/signer';
import { DEV_PHRASE } from '@polkadot-labs/hdkd-helpers';

const keyring = sr25519CreateDerive(DEV_PHRASE);

// Alice
const aliceSigner = getPolkadotSigner(
    keyring.derive("//Alice"),
    "Alice",
    42
);

// Bob
const bobSigner = getPolkadotSigner(
    keyring.derive("//Bob"),
    "Bob",
    42
);
</code></pre>
<h3 id="production-accounts"><a class="header" href="#production-accounts">Production Accounts</a></h3>
<p>For production, use a seed phrase or mnemonic:</p>
<pre><code class="language-typescript">import { sr25519CreateDerive } from '@polkadot-labs/hdkd';
import { getPolkadotSigner } from 'polkadot-api/signer';

const keyring = sr25519CreateDerive(
    "bottom drive obey lake curtain smoke basket hold race lonely fit walk"
);

const signer = getPolkadotSigner(
    keyring.derive("//0"), // Derive first account
    "My Account",
    42 // Bulletin chain ID
);
</code></pre>
<h3 id="browser-wallet-extension"><a class="header" href="#browser-wallet-extension">Browser Wallet Extension</a></h3>
<p>For browser applications with wallet extensions:</p>
<pre><code class="language-typescript">import { getInjectedExtensions, connectInjectedExtension } from 'polkadot-api/pjs-signer';

// Get available extensions
const extensions = getInjectedExtensions();

// Connect to an extension (e.g., Talisman, Polkadot.js)
const extension = await connectInjectedExtension('polkadot-js');

// Get accounts
const accounts = extension.getAccounts();

// Create client with first account
const client = new AsyncBulletinClient(api, accounts[0].polkadotSigner);
</code></pre>
<h2 id="multiple-accounts"><a class="header" href="#multiple-accounts">Multiple Accounts</a></h2>
<p>When you need to use different accounts (e.g., Alice for authorization, Bob for storage), create separate clients:</p>
<pre><code class="language-typescript">// Client for Alice (sudo account)
const aliceClient = new AsyncBulletinClient(api, aliceSigner);

// Client for Bob (regular user)
const bobClient = new AsyncBulletinClient(api, bobSigner);

// Alice authorizes Bob
const bobAddress = "5FHneW46xGXgs5mUiveU4sbTyGBzmstUspZC92UhjJM694ty";
await aliceClient.authorizeAccount(bobAddress, 100, BigInt(10_000_000));

// Bob stores data
const result = await bobClient.store(data).send();
</code></pre>
<h2 id="direct-transaction-submission"><a class="header" href="#direct-transaction-submission">Direct Transaction Submission</a></h2>
<p>The SDK handles transaction submission internally. However, if you need to submit transactions manually (e.g., for custom batching), you can use PAPI directly:</p>
<pre><code class="language-typescript">// Prepare data with core SDK (BulletinClient)
import { BulletinClient } from '@bulletin/sdk';

const prepClient = new BulletinClient({ endpoint: 'ws://localhost:9944' });
const operation = await prepClient.prepareStore(data);

// Submit via PAPI
const tx = api.tx.TransactionStorage.store({
    data: operation.data
});

const result = await tx.signAndSubmit(signer);
const finalized = await result.waitFor('finalized');

console.log('Block hash:', finalized.blockHash);
</code></pre>
<h2 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h2>
<p>Handle blockchain errors properly:</p>
<pre><code class="language-typescript">import { BulletinError } from '@bulletin/sdk';

try {
    const result = await client.store(data).send();
    console.log('Success:', result.cid.toString());
} catch (error) {
    if (error instanceof BulletinError) {
        console.error('Bulletin error:', error.code);
        console.error('Message:', error.message);
        console.error('Details:', error.cause);
    } else {
        console.error('Unexpected error:', error);
    }
}
</code></pre>
<h2 id="configuration-options-2"><a class="header" href="#configuration-options-2">Configuration Options</a></h2>
<p>Customize client behavior:</p>
<pre><code class="language-typescript">const client = new AsyncBulletinClient(api, signer, {
    defaultChunkSize: 1024 * 1024, // 1 MiB chunks
    maxParallel: 8, // Upload 8 chunks in parallel
    createManifest: true, // Create DAG-PB manifest
    chunkingThreshold: 2 * 1024 * 1024, // Auto-chunk files &gt; 2 MiB
    checkAuthorizationBeforeUpload: true, // Validate auth before upload
});
</code></pre>
<h2 id="cleanup"><a class="header" href="#cleanup">Cleanup</a></h2>
<p>Always clean up connections when done:</p>
<pre><code class="language-typescript">// Store data
const result = await client.store(data).send();

// Cleanup
await papiClient.destroy();
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
